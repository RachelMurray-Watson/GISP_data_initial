{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'CLINIC', 'YEAR', 'GENDERSP',\n",
      "       'Susceptible', 'REGION', 'MSM', 'MSMW', 'MSW', 'Oth/Unk/Missing',\n",
      "       'Midwest', 'Northeast', 'Southeast', 'Southwest', 'West', 'PREV_REGION',\n",
      "       'PREV_CLINIC', 'DELTA_REGION', 'DELTA_CLINIC', 'Count_Exceeds_75',\n",
      "       'Trend_N_greater_75'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#%reset\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import os \n",
    "from matplotlib.patches import Polygon\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import loguniform\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, roc_auc_score\n",
    "#from Functions_AMR_gonorrhea import effective_unnecessary_threshold, get_best_hyperparameters, get_best_features, get_test_train_data, get_feature_effects, f1_mcc_score_threshold\n",
    "hfont = {'fontname':'Helvetica'}\n",
    "import pickle\n",
    "## read data \n",
    "CIP_data_no_drop = pd.read_csv(\"CIP_data_encode_prev_not_dropped.csv\")\n",
    "print(CIP_data_no_drop.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "################################ Get hyperparameters and best features for each model  ###########################\n",
    "#### Loop set up \n",
    "threshold_seq = np.linspace(0,1,101)\n",
    "test_years = [2005, 2006, 2007, 2008, 2009, 2010]  #np.array(range(2005, 2011))\n",
    "oversample = RandomOverSampler(sampling_strategy = 'minority',random_state=42) #need for neural network and random forest\n",
    "model_types = [\"Logistic_regression\",  \"Random_forest\", \"Neural_network\"]\n",
    "i = 0\n",
    "\n",
    "# logistic regression - random initial parameters\n",
    "model_lr = LogisticRegression(class_weight = 'balanced', max_iter=4000, solver = \"lbfgs\", C = 0.27, penalty = 'l2')\n",
    "# random forest - random initial parameters\n",
    "model_rf = RandomForestClassifier(n_estimators = 171, min_samples_split = 1, min_samples_leaf=1, max_features = 'sqrt', max_depth = 89, random_state = 10)\n",
    "# neural network - random parameters\n",
    "model_nn = MLPClassifier(solver = 'lbfgs', activation = 'tanh', max_iter = 3000 ,hidden_layer_sizes= 12, alpha =1.291549665014884, random_state=10, learning_rate = 'adaptive' )\n",
    "unfitted_models = [model_lr, model_rf, model_nn]\n",
    "\n",
    "### Hyperparameter tuning\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,  n_repeats=10,random_state=1) ## 10-fold cross validations\n",
    "# logistic regression \n",
    "space_lr = dict()\n",
    "space_lr['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space_lr['penalty'] = ['l1', 'l2']\n",
    "space_lr['C'] = np.arange(0, 100, .01)\n",
    "best_hyperparameters_by_year[model_type] = {}\n",
    "# random forest \n",
    "space_rf = dict()\n",
    "space_rf['n_estimators'] = np.arange(100, 201, 1)\n",
    "space_rf['max_depth'] = np.arange(1, 200, 1)\n",
    "space_rf['min_samples_split'] = np.arange(1, 25, 1)\n",
    "space_rf['min_samples_leaf'] = np.arange(1, 25, 1)\n",
    "best_hyperparameters_by_year[model_type] = {}\n",
    "# neural network \n",
    "space_nn = dict()\n",
    "space_nn['solver'] = ['lbfgs', 'sgd', 'adam']\n",
    "space_nn['activation'] = ['tanh', 'relu']\n",
    "space_nn['alpha'] = np.logspace(-1, 1, 10)\n",
    "space_nn['learning_rate'] = ['constant','adaptive']\n",
    "space_nn['hidden_layer_sizes'] = [(4,), (6,), (8,), (10,), (12,), (13,), (14,)]\n",
    "best_hyperparameters_by_year_nn = {}\n",
    "\n",
    "space = [space_lr, space_rf, space_nn]\n",
    "best_hyperparameters_by_year = [best_hyperparameters_by_year[model_type], best_hyperparameters_by_year[model_type],best_hyperparameters_by_year_nn]\n",
    "\n",
    "### Feature Engineering\n",
    "feature_names = ['MSM','MSMW', 'MSW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West', 'Midwest','PREV_REGION', 'PREV_CLINIC', 'DELTA_REGION',  'Count_Exceeds_75', 'Trend_N_greater_75']\n",
    "best_features_by_year_lr = {}\n",
    "best_features_by_year_rf = {}\n",
    "best_features_by_year_nn = {}\n",
    "best_features_by_year = [best_features_by_year_lr, best_features_by_year_rf, best_features_by_year_nn]\n",
    "\n",
    "imporances_all_models = pd.DataFrame(0, index = feature_names, columns=np.arange(len(test_years)*3))\n",
    "indices_for_importance = [6,12,0] ## need to be in correct order \n",
    "imporances_all_models_sd = pd.DataFrame(0, index = feature_names, columns=np.arange(len(test_years)*3))\n",
    "\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy='minority', random_state=10)\n",
    "\n",
    "def get_test_train_data(CIP_data_no_drop, year, feature_names, years_train, model_type):\n",
    "\n",
    "    train_data = CIP_data_no_drop.loc[CIP_data_no_drop[\"YEAR\"].isin(years_train)]\n",
    "    X_train = train_data[\n",
    "        feature_names\n",
    "    ]  # need to consider all columns BEFORE feature engineering\n",
    "    y_train = 1 - train_data[\"Susceptible\"]\n",
    "    # test\n",
    "    test_data = CIP_data_no_drop.loc[CIP_data_no_drop[\"YEAR\"].isin([year])]\n",
    "    X_test = test_data[feature_names]\n",
    "    y_test = 1 - test_data[\"Susceptible\"]\n",
    "    cipro_R_prev = y_test.sum() / len(y_test)\n",
    "    if (model_type == 1) | (model_type == 2):\n",
    "        X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "        # X_test, y_test = oversample.fit_resample(X_test, y_test)\n",
    "        print(\"Oversample\")\n",
    "    return (test_data, train_data, X_train, y_train, X_test, y_test, cipro_R_prev)\n",
    "\n",
    "def get_feature_effects(all_features, important_features, model_fit, X_train, y_train):\n",
    "    PI = permutation_importance(\n",
    "        model_fit, X_train, y_train, n_repeats=10, random_state=0\n",
    "    )\n",
    "    feature_importances = []\n",
    "    for feature in all_features:\n",
    "        if feature in important_features:\n",
    "            feature_importances.append(PI.importances_mean[important_features.index(feature)])\n",
    "        else:\n",
    "            feature_importances.append(0)\n",
    "    return feature_importances\n",
    "\n",
    "def get_best_features(feature_names, model_fit, X_train, y_train):\n",
    "    PI = permutation_importance(\n",
    "        model_fit, X_train, y_train, n_repeats=10, random_state=0\n",
    "    )\n",
    "    important_features = []\n",
    "    for q in PI.importances_mean.argsort()[::-1]:\n",
    "        if PI.importances_mean[q] - PI.importances_std[q] >0:\n",
    "            important_features.append(\n",
    "                feature_names[q]\n",
    "            )  # works cos they are in same order as the x columns\n",
    "    return important_features\n",
    "\n",
    "def get_feature_effects_sd(feature_names, important_features,model_fit, X_train, y_train):\n",
    "    PI = permutation_importance(\n",
    "        model_fit, X_train, y_train, n_repeats=10, random_state=42\n",
    "    )\n",
    "\n",
    "    return PI.importances_std\n",
    "\n",
    "def get_best_hyperparameters(model, cv, space, X_train, y_train):\n",
    "    search = RandomizedSearchCV(\n",
    "        model, space, scoring=\"roc_auc\", n_iter=20, n_jobs=-1, cv=cv, random_state=1\n",
    "    )\n",
    "    result = search.fit(X_train, y_train)\n",
    "    return result.best_params_\n",
    "\n",
    "### ROC by year \n",
    "ROC_by_year_rf = {}\n",
    "ROC_by_year_lr = {}\n",
    "ROC_by_year_nn = {}\n",
    "\n",
    "ROC_by_year = [ROC_by_year_lr, ROC_by_year_rf, ROC_by_year_nn]\n",
    "\n",
    "\n",
    "def get_test_train_data(CIP_data_no_drop, year, feature_names, years_train, model_type):\n",
    "    feature_names_with_weight = feature_names.copy()\n",
    "    feature_names_with_weight.extend(['weight'])\n",
    "    train_data = CIP_data_no_drop.loc[CIP_data_no_drop[\"YEAR\"].isin(years_train)]\n",
    "    X_train = train_data[feature_names_with_weight]  # need to consider all columns BEFORE feature engineering\n",
    "    y_train = 1 - train_data[\"Susceptible\"]\n",
    "    # test\n",
    "    test_data = CIP_data_no_drop.loc[CIP_data_no_drop[\"YEAR\"].isin([year])]\n",
    "    X_test = test_data[feature_names_with_weight]\n",
    "    y_test = 1 - test_data[\"Susceptible\"]\n",
    "    cipro_R_prev = y_test.sum() / len(y_test)\n",
    "\n",
    "    if (model_type == 1) | (model_type == 2):\n",
    "        X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "        # X_test, y_test = oversample.fit_resample(X_test, y_test)\n",
    "        print(\"Oversample\")\n",
    "    weights_train = X_train[\"weight\"]\n",
    "    X_train  = X_train.drop(\"weight\", axis = 1)\n",
    "    X_test = X_test.drop(\"weight\", axis = 1)\n",
    "\n",
    "    return (test_data, train_data, X_train, y_train, X_test, y_test, cipro_R_prev, weights_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "200 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.89832695 0.89831798 0.89832333 0.89832695 0.89832584        nan\n",
      "        nan 0.89832572 0.89833079 0.8983299  0.89831419 0.89832913\n",
      " 0.89831258 0.89832743 0.89832676 0.89833022 0.89832703 0.89832999\n",
      " 0.89832982 0.89833226]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "200 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.84487805 0.84487643 0.84486791 0.84487805 0.84487643        nan\n",
      "        nan 0.84487805 0.8448756  0.84487643 0.84487552 0.84487748\n",
      " 0.84487775 0.84487643 0.84487797 0.844877   0.84487805 0.84487805\n",
      " 0.84487797 0.8448756 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7201573387567364\n",
      "2006\n",
      "Hyperparameters1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "200 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.82283004 0.82283004 0.82283004 0.82283004 0.82283004        nan\n",
      "        nan 0.82283004 0.82283004 0.82283004 0.82283004 0.82283004\n",
      " 0.82283004 0.82283004 0.82283004 0.82283004 0.82283004 0.82283004\n",
      " 0.82283004 0.82283004]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7163785879790616\n",
      "2007\n",
      "Hyperparameters1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "200 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.80239297 0.80239297 0.80239297 0.80239297 0.80239297        nan\n",
      "        nan 0.80239297 0.80239297 0.80239297 0.80239297 0.80239297\n",
      " 0.80239297 0.80239297 0.80239297 0.80239297 0.80239297 0.80239297\n",
      " 0.80239297 0.80239297]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6859769375400482\n",
      "2008\n",
      "Hyperparameters1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "200 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.79712166 0.79712166 0.79707682 0.79712166 0.79712166        nan\n",
      "        nan 0.79712166 0.79712166 0.79712166 0.79712166 0.79712166\n",
      " 0.79712187 0.79712166 0.79712166 0.79712166 0.79712166 0.79712148\n",
      " 0.79712166 0.79712187]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6768972801001382\n",
      "2009\n",
      "Hyperparameters1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "200 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.81905235 0.819053   0.81905309 0.8190523  0.81905371        nan\n",
      "        nan 0.81905274 0.81905556 0.81905535 0.8190511  0.81905496\n",
      " 0.81904946 0.81905328 0.81905384 0.81905569 0.81905249 0.81905313\n",
      " 0.81905605 0.81905398]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6455044050644695\n",
      "2010\n",
      "Hyperparameters1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "200 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/rem76/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.79727865 0.79728056 0.79728498 0.79727903 0.79728025        nan\n",
      "        nan 0.79728039 0.79728271 0.79728382 0.79727932 0.7972834\n",
      " 0.79727605 0.79727921 0.79727718 0.79728411 0.79727935 0.79728129\n",
      " 0.79728261 0.79728312]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6585171433264794\n"
     ]
    }
   ],
   "source": [
    "# Just LR\n",
    "model_lr = LogisticRegression(class_weight = 'balanced', max_iter=4000, solver = \"lbfgs\", C = 0.27, penalty = 'l2')\n",
    "\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['l1', 'l2']\n",
    "space['C'] = np.arange(0, 100, .01)\n",
    "i = 0\n",
    "for year in test_years: \n",
    "    print(year)\n",
    "    model_type = 0\n",
    "    years_train = np.array(range(year - 5, year))\n",
    "\n",
    "    CIP_data_training_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin(years_train)]\n",
    "    CIP_data_testing_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin([year])]\n",
    "    # first do for all clinics \n",
    "\n",
    "    counts = CIP_data_training_years.groupby(['YEAR', 'CLINIC']).size().reset_index(name='Count')\n",
    "    counts_by_year = CIP_data_training_years.groupby(['YEAR']).size().reset_index(name='Count')\n",
    "\n",
    "    merged_counts = counts.merge(counts_by_year, on='YEAR', suffixes=('_counts', '_counts_by_year'))\n",
    "\n",
    "    # Calculate the sum of all counts in the counts dataframe\n",
    "    total_counts = counts['Count'].sum()\n",
    "\n",
    "    # Calculate the 'weight' column as Count_counts / total_counts\n",
    "    merged_counts['weight'] = merged_counts['Count_counts'] / total_counts\n",
    "    # Calculate the 'weight' column as Count_counts / rolling sum of the previous 5 years\n",
    "\n",
    "    # Merge the 'weight' column back to the original DataFrame\n",
    "    CIP_data_no_drop = CIP_data_no_drop.merge(merged_counts[['YEAR', 'CLINIC', 'weight']], on=['YEAR', 'CLINIC'], how='left')\n",
    "\n",
    " \n",
    "    test_data, train_data, X_train, y_train, X_test, y_test, cipro_R_prev, weights_train =  get_test_train_data(CIP_data_no_drop = CIP_data_no_drop, year = year, feature_names = feature_names, years_train = years_train, model_type = model_type)\n",
    "    if year == 2005: \n",
    "    ## before fitting the model, do hyperparameter tuning \n",
    "        best_hyperparameters1 = get_best_hyperparameters(model_lr, cv, space, X_train, y_train)\n",
    "    model_lr = LogisticRegression(class_weight = 'balanced', max_iter=5000, solver = best_hyperparameters1['solver'], C = best_hyperparameters1['C'], penalty = best_hyperparameters1['penalty'])\n",
    "    \n",
    "    print(\"Hyperparameters1\")\n",
    "    ## fit model w/hyperparameters \n",
    "    model_fit = model_lr.fit(X_train, y_train, sample_weight = weights_train)\n",
    "\n",
    "    ## now also need to do feature engineering\n",
    "    important_features = get_best_features(feature_names, model_fit, X_train, y_train)\n",
    "    best_features_by_year[model_type].__setitem__(year, important_features) \n",
    "    imporances_all_models[i + indices_for_importance[model_type]] = get_feature_effects(feature_names, important_features, model_fit, X_train, y_train) #want it to be the correct block for each model\n",
    "    imporances_all_models_sd[i + indices_for_importance[model_type]] = get_feature_effects(feature_names, important_features, model_fit, X_train, y_train) #want it to be the correct block for each model\n",
    "\n",
    "    # get new test/train data and hyperparameter tuning round 2 \n",
    "\n",
    "    test_data, train_data, X_train, y_train, X_test, y_test, cipro_R_prev, weights_train =  get_test_train_data(CIP_data_no_drop = CIP_data_no_drop, year = year, feature_names = important_features, years_train = years_train, model_type = model_type)\n",
    "    \n",
    "    best_hyperparameters2 = get_best_hyperparameters(model_lr, cv, space, X_train, y_train)\n",
    "    best_hyperparameters_by_year[model_type].__setitem__(year, best_hyperparameters2) \n",
    "\n",
    "\n",
    "    ## fit model w/hyperparameters \n",
    "    model_lr = LogisticRegression(class_weight = 'balanced', max_iter=5000, solver = best_hyperparameters2['solver'], C = best_hyperparameters2['C'], penalty = best_hyperparameters2['penalty'])\n",
    "\n",
    "    model_fit_train = model_lr.fit(X_train, y_train, sample_weight = weights_train)\n",
    "    y_predict_test = model_fit_train.predict(X_test)\n",
    "    y_predict_proba = model_fit_train.predict_proba(X_test)\n",
    " \n",
    "    ROC= metrics.roc_auc_score(y_test, y_predict_test)\n",
    "    ROC_by_year[model_type].__setitem__(year, ROC)\n",
    "    CIP_data_no_drop = CIP_data_no_drop.drop('weight', axis = 1)\n",
    "    print(ROC)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{2005: 0.7201573387567364, 2006: 0.7163785879790616, 2007: 0.6859769375400482, 2008: 0.6768972801001382, 2009: 0.6455044050644695, 2010: 0.6585171433264794}, {}, {}]\n",
      "[{2005: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 55.0}, 2006: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 55.0}, 2007: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 55.0}, 2008: {'solver': 'liblinear', 'penalty': 'l2', 'C': 12.91}, 2009: {'solver': 'liblinear', 'penalty': 'l1', 'C': 90.91}, 2010: {'solver': 'liblinear', 'penalty': 'l1', 'C': 8.65}}, {}, {}]\n",
      "[{2005: ['West', 'Southwest', 'Northeast', 'MSW', 'MSM', 'Trend_N_greater_75'], 2006: ['West', 'Southwest', 'Southeast', 'MSW', 'Northeast'], 2007: ['MSW', 'Oth/Unk/Missing', 'West'], 2008: ['West', 'MSW', 'Northeast', 'Oth/Unk/Missing', 'Trend_N_greater_75', 'Southeast'], 2009: ['West', 'PREV_CLINIC', 'MSW', 'MSM', 'DELTA_REGION', 'PREV_REGION', 'Southeast', 'Northeast', 'Oth/Unk/Missing', 'Trend_N_greater_75', 'Count_Exceeds_75'], 2010: ['MSM', 'PREV_CLINIC', 'DELTA_REGION', 'West', 'MSW', 'PREV_REGION', 'MSMW', 'Southeast', 'Southwest', 'Count_Exceeds_75']}, {}, {}]\n"
     ]
    }
   ],
   "source": [
    "print(ROC_by_year)\n",
    "print(best_hyperparameters_by_year)\n",
    "print(best_features_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_by_year = [{2005: 0.7201573387567364, 2006: 0.7163785879790616, 2007: 0.6859769375400482, 2008: 0.6768972801001382, 2009: 0.6455044050644695, 2010: 0.6585171433264794}, {}, {}]\n",
    "best_hyperparameters_by_year = [{2005: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 55.0}, 2006: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 55.0}, 2007: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 55.0}, 2008: {'solver': 'liblinear', 'penalty': 'l2', 'C': 12.91}, 2009: {'solver': 'liblinear', 'penalty': 'l1', 'C': 90.91}, 2010: {'solver': 'liblinear', 'penalty': 'l1', 'C': 8.65}}, {}, {}]\n",
    "best_features_by_year =[{2005: ['West', 'Southwest', 'Northeast', 'MSW', 'MSM', 'Trend_N_greater_75'], 2006: ['West', 'Southwest', 'Southeast', 'MSW', 'Northeast'], 2007: ['MSW', 'Oth/Unk/Missing', 'West'], 2008: ['West', 'MSW', 'Northeast', 'Oth/Unk/Missing', 'Trend_N_greater_75', 'Southeast'], 2009: ['West', 'PREV_CLINIC', 'MSW', 'MSM', 'DELTA_REGION', 'PREV_REGION', 'Southeast', 'Northeast', 'Oth/Unk/Missing', 'Trend_N_greater_75', 'Count_Exceeds_75'], 2010: ['MSM', 'PREV_CLINIC', 'DELTA_REGION', 'West', 'MSW', 'PREV_REGION', 'MSMW', 'Southeast', 'Southwest', 'Count_Exceeds_75']}, {}, {}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imporances_all_models.write_csv('imporances_all_models_with_weights_and_count_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "Oversample\n",
      "Oversample\n",
      "2006\n",
      "Oversample\n",
      "Oversample\n",
      "2007\n",
      "Oversample\n",
      "Oversample\n",
      "2008\n",
      "Oversample\n",
      "Oversample\n",
      "2009\n",
      "Oversample\n",
      "Oversample\n",
      "2010\n",
      "Oversample\n",
      "Oversample\n"
     ]
    }
   ],
   "source": [
    "## Just RF\n",
    "model_rf = RandomForestClassifier(n_estimators = 171, min_samples_split = 1, min_samples_leaf=1, max_features = 'sqrt', max_depth = 89, random_state = 10)\n",
    "\n",
    "space = dict()\n",
    "space['n_estimators'] = np.arange(1, 201, 1)\n",
    "space['max_depth'] = np.arange(1, 200, 1)\n",
    "space['min_samples_split'] = np.arange(1, 100, 1)\n",
    "space['min_samples_leaf'] = np.arange(1, 100, 1)\n",
    "test_years = [2005, 2006, 2007, 2008, 2009, 2010]  #np.array(range(2005, 2011))\n",
    "\n",
    "i = 0\n",
    "for year in test_years: \n",
    "    print(year)\n",
    "    model_type = 1\n",
    "    years_train = np.array(range(year - 5, year))\n",
    "\n",
    "    CIP_data_training_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin(years_train)]\n",
    "    CIP_data_testing_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin([year])]\n",
    "    # first do for all clinics \n",
    "    counts = CIP_data_training_years.groupby(['YEAR', 'CLINIC']).size().reset_index(name='Count')\n",
    "    counts_by_year = CIP_data_training_years.groupby(['YEAR']).size().reset_index(name='Count')\n",
    "\n",
    "    merged_counts = counts.merge(counts_by_year, on='YEAR', suffixes=('_counts', '_counts_by_year'))\n",
    "\n",
    "    # Calculate the sum of all counts in the counts dataframe\n",
    "    total_counts = counts['Count'].sum()\n",
    "\n",
    "    # Calculate the 'weight' column as Count_counts / total_counts\n",
    "    merged_counts['weight'] = merged_counts['Count_counts'] / total_counts\n",
    "    # Calculate the 'weight' column as Count_counts / rolling sum of the previous 5 years\n",
    "\n",
    "    # Merge the 'weight' column back to the original DataFrame\n",
    "    CIP_data_no_drop = CIP_data_no_drop.merge(merged_counts[['YEAR', 'CLINIC', 'weight']], on=['YEAR', 'CLINIC'], how='left')\n",
    "\n",
    " \n",
    "    test_data, train_data, X_train, y_train, X_test, y_test, cipro_R_prev, weights_train =  get_test_train_data(CIP_data_no_drop = CIP_data_no_drop, year = year, feature_names = feature_names, years_train = years_train, model_type = model_type)\n",
    "\n",
    "    ## before fitting the model, do hyperparameter tuning \n",
    "    if year == 2005: \n",
    "        best_hyperparameters1 = get_best_hyperparameters(model_rf, cv, space, X_train, y_train)\n",
    "    model_rf = RandomForestClassifier(n_estimators = best_hyperparameters1['n_estimators'], min_samples_split = best_hyperparameters1['min_samples_split'], min_samples_leaf=best_hyperparameters1['min_samples_leaf'], max_features = 'sqrt', max_depth = best_hyperparameters1['max_depth'], random_state = 10)\n",
    "    \n",
    "     \n",
    "    ## fit model w/hyperparameters \n",
    "    model_fit = model_rf.fit(X_train, y_train, sample_weight = weights_train)\n",
    "\n",
    "    ## now also need to do feature engineering\n",
    "    important_features = get_best_features(feature_names, model_fit, X_train, y_train)\n",
    "    best_features_by_year[model_type].__setitem__(year, important_features) \n",
    "    imporances_all_models[i + indices_for_importance[model_type]] = get_feature_effects(feature_names, important_features, model_fit, X_train, y_train) #want it to be the correct block for each model\n",
    "    imporances_all_models_sd[i + indices_for_importance[model_type]] = get_feature_effects(feature_names, important_features, model_fit, X_train, y_train) #want it to be the correct block for each model\n",
    "\n",
    "    # get new test/train data and hyperparameter tuning round 2 \n",
    "\n",
    "    test_data, train_data, X_train, y_train, X_test, y_test, cipro_R_prev, weights_train =  get_test_train_data(CIP_data_no_drop = CIP_data_no_drop, year = year, feature_names = important_features, years_train = years_train, model_type = model_type)\n",
    "    \n",
    "    best_hyperparameters2 = get_best_hyperparameters(model_rf, cv, space, X_train, y_train)\n",
    "    best_hyperparameters_by_year[model_type].__setitem__(year, best_hyperparameters2) \n",
    "\n",
    "\n",
    "\n",
    "    ## fit model w/hyperparameters \n",
    "    model_rf = RandomForestClassifier(n_estimators = best_hyperparameters2['n_estimators'], min_samples_split = best_hyperparameters2['min_samples_split'], min_samples_leaf=best_hyperparameters2['min_samples_leaf'], max_features = 'sqrt', max_depth = best_hyperparameters2['max_depth'], random_state = 10)\n",
    "\n",
    "    model_fit_train = model_rf.fit(X_train, y_train, sample_weight = weights_train)\n",
    "    y_predict_test = model_fit_train.predict(X_test)\n",
    "    y_predict_proba = model_fit_train.predict_proba(X_test)\n",
    " \n",
    "    ROC= metrics.roc_auc_score(y_test, y_predict_test)\n",
    "    ROC_by_year[model_type].__setitem__(year, ROC)\n",
    "    CIP_data_no_drop = CIP_data_no_drop.drop('weight', axis = 1)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{2005: 0.7201573387567364, 2006: 0.7163785879790616, 2007: 0.6859769375400482, 2008: 0.6768972801001382, 2009: 0.6455044050644695, 2010: 0.6585171433264794}, {2005: 0.7422861470301229, 2006: 0.716008241481748, 2007: 0.6904656174878919, 2008: 0.6891381333611495, 2009: 0.6675168178659392, 2010: 0.6670052565692955}, {}]\n",
      "[{2005: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 55.0}, 2006: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 55.0}, 2007: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 55.0}, 2008: {'solver': 'liblinear', 'penalty': 'l2', 'C': 12.91}, 2009: {'solver': 'liblinear', 'penalty': 'l1', 'C': 90.91}, 2010: {'solver': 'liblinear', 'penalty': 'l1', 'C': 8.65}}, {2005: {'n_estimators': 181, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 99}, 2006: {'n_estimators': 181, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 99}, 2007: {'n_estimators': 181, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 99}, 2008: {'n_estimators': 181, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 99}, 2009: {'n_estimators': 181, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 99}, 2010: {'n_estimators': 181, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 99}}, {}]\n",
      "[{2005: ['West', 'Southwest', 'Northeast', 'MSW', 'MSM', 'Trend_N_greater_75'], 2006: ['West', 'Southwest', 'Southeast', 'MSW', 'Northeast'], 2007: ['MSW', 'Oth/Unk/Missing', 'West'], 2008: ['West', 'MSW', 'Northeast', 'Oth/Unk/Missing', 'Trend_N_greater_75', 'Southeast'], 2009: ['West', 'PREV_CLINIC', 'MSW', 'MSM', 'DELTA_REGION', 'PREV_REGION', 'Southeast', 'Northeast', 'Oth/Unk/Missing', 'Trend_N_greater_75', 'Count_Exceeds_75'], 2010: ['MSM', 'PREV_CLINIC', 'DELTA_REGION', 'West', 'MSW', 'PREV_REGION', 'MSMW', 'Southeast', 'Southwest', 'Count_Exceeds_75']}, {2005: ['PREV_CLINIC', 'MSM', 'MSW', 'DELTA_REGION', 'PREV_REGION', 'West', 'MSMW', 'Count_Exceeds_75', 'Midwest', 'Trend_N_greater_75', 'Southeast', 'Oth/Unk/Missing'], 2006: ['PREV_CLINIC', 'MSW', 'MSM', 'PREV_REGION', 'DELTA_REGION', 'MSMW', 'West', 'Trend_N_greater_75', 'Southeast', 'Southwest', 'Oth/Unk/Missing', 'Midwest', 'Count_Exceeds_75'], 2007: ['PREV_CLINIC', 'MSW', 'MSM', 'DELTA_REGION', 'PREV_REGION', 'West', 'MSMW', 'Northeast', 'Trend_N_greater_75', 'Midwest', 'Southwest', 'Oth/Unk/Missing', 'Southeast', 'Count_Exceeds_75'], 2008: ['PREV_CLINIC', 'MSW', 'MSM', 'PREV_REGION', 'DELTA_REGION', 'MSMW', 'West', 'Southwest', 'Midwest', 'Trend_N_greater_75', 'Northeast', 'Oth/Unk/Missing', 'Count_Exceeds_75', 'Southeast'], 2009: ['PREV_CLINIC', 'MSW', 'MSM', 'PREV_REGION', 'DELTA_REGION', 'MSMW', 'Midwest', 'West', 'Southwest', 'Southeast', 'Oth/Unk/Missing', 'Count_Exceeds_75', 'Trend_N_greater_75', 'Northeast'], 2010: ['PREV_CLINIC', 'MSW', 'MSM', 'PREV_REGION', 'DELTA_REGION', 'MSMW', 'West', 'Southeast', 'Midwest', 'Southwest', 'Count_Exceeds_75', 'Northeast', 'Oth/Unk/Missing', 'Trend_N_greater_75']}, {}]\n"
     ]
    }
   ],
   "source": [
    "print(ROC_by_year)\n",
    "print(best_hyperparameters_by_year)\n",
    "print(best_features_by_year)\n",
    "imporances_all_models.to_csv('imporances_all_models_with_weights_and_count_features.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auROC, features, and hyperparameters with weights caclulated by training set and extra features \n",
    "LR and RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_by_year =[{2005: 0.7201573387567364, 2006: 0.7163785879790616, 2007: 0.6859769375400482, 2008: 0.6768972801001382, 2009: 0.6455044050644695, 2010: 0.6585171433264794}, {2005: 0.7422861470301229, 2006: 0.716008241481748, 2007: 0.6904656174878919, 2008: 0.6891381333611495, 2009: 0.6675168178659392, 2010: 0.6670052565692955}, {}]\n",
    "best_hyperparameters_by_year = [{2005: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 55.0}, 2006: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 55.0}, 2007: {'solver': 'newton-cg', 'penalty': 'l2', 'C': 55.0}, 2008: {'solver': 'liblinear', 'penalty': 'l2', 'C': 12.91}, 2009: {'solver': 'liblinear', 'penalty': 'l1', 'C': 90.91}, 2010: {'solver': 'liblinear', 'penalty': 'l1', 'C': 8.65}}, {2005: {'n_estimators': 181, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 99}, 2006: {'n_estimators': 181, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 99}, 2007: {'n_estimators': 181, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 99}, 2008: {'n_estimators': 181, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 99}, 2009: {'n_estimators': 181, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 99}, 2010: {'n_estimators': 181, 'min_samples_split': 20, 'min_samples_leaf': 5, 'max_depth': 99}}, {}]\n",
    "best_features_by_year =[{2005: ['West', 'Southwest', 'Northeast', 'MSW', 'MSM', 'Trend_N_greater_75'], 2006: ['West', 'Southwest', 'Southeast', 'MSW', 'Northeast'], 2007: ['MSW', 'Oth/Unk/Missing', 'West'], 2008: ['West', 'MSW', 'Northeast', 'Oth/Unk/Missing', 'Trend_N_greater_75', 'Southeast'], 2009: ['West', 'PREV_CLINIC', 'MSW', 'MSM', 'DELTA_REGION', 'PREV_REGION', 'Southeast', 'Northeast', 'Oth/Unk/Missing', 'Trend_N_greater_75', 'Count_Exceeds_75'], 2010: ['MSM', 'PREV_CLINIC', 'DELTA_REGION', 'West', 'MSW', 'PREV_REGION', 'MSMW', 'Southeast', 'Southwest', 'Count_Exceeds_75']}, {2005: ['PREV_CLINIC', 'MSM', 'MSW', 'DELTA_REGION', 'PREV_REGION', 'West', 'MSMW', 'Count_Exceeds_75', 'Midwest', 'Trend_N_greater_75', 'Southeast', 'Oth/Unk/Missing'], 2006: ['PREV_CLINIC', 'MSW', 'MSM', 'PREV_REGION', 'DELTA_REGION', 'MSMW', 'West', 'Trend_N_greater_75', 'Southeast', 'Southwest', 'Oth/Unk/Missing', 'Midwest', 'Count_Exceeds_75'], 2007: ['PREV_CLINIC', 'MSW', 'MSM', 'DELTA_REGION', 'PREV_REGION', 'West', 'MSMW', 'Northeast', 'Trend_N_greater_75', 'Midwest', 'Southwest', 'Oth/Unk/Missing', 'Southeast', 'Count_Exceeds_75'], 2008: ['PREV_CLINIC', 'MSW', 'MSM', 'PREV_REGION', 'DELTA_REGION', 'MSMW', 'West', 'Southwest', 'Midwest', 'Trend_N_greater_75', 'Northeast', 'Oth/Unk/Missing', 'Count_Exceeds_75', 'Southeast'], 2009: ['PREV_CLINIC', 'MSW', 'MSM', 'PREV_REGION', 'DELTA_REGION', 'MSMW', 'Midwest', 'West', 'Southwest', 'Southeast', 'Oth/Unk/Missing', 'Count_Exceeds_75', 'Trend_N_greater_75', 'Northeast'], 2010: ['PREV_CLINIC', 'MSW', 'MSM', 'PREV_REGION', 'DELTA_REGION', 'MSMW', 'West', 'Southeast', 'Midwest', 'Southwest', 'Count_Exceeds_75', 'Northeast', 'Oth/Unk/Missing', 'Trend_N_greater_75']}, {}]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciKt Learn MLP classifier doesn't allow for sample weights, so need to use keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ... (Other parts of the code remain unchanged)\n",
    "\n",
    "def create_mlp_model(activation, alpha, learning_rate, hidden_layer_sizes):\n",
    "    model = Sequential()\n",
    "    for layer_size in hidden_layer_sizes:\n",
    "        model.add(Dense(layer_size, activation=activation))\n",
    "    model.add(Dense(1, activation=activation))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "space = dict()\n",
    "space['activation'] = ['tanh', 'relu', 'sigmoid' ]\n",
    "space['alpha'] = np.logspace(-1, 1, 1000)\n",
    "space['learning_rate'] = ['constant', 'adaptive']\n",
    "space['hidden_layer_sizes'] = [(8,), (9,), (10,), (11,), (12,), (13,), (14,)]\n",
    "\n",
    "i = 2\n",
    "for year in test_years: \n",
    "    print(year)\n",
    "    model_type = 2\n",
    "    years_train = np.array(range(year - 5, year))\n",
    "\n",
    "    CIP_data_training_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin(years_train)]\n",
    "    CIP_data_testing_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin([year])]\n",
    "    # first do for all clinics \n",
    "    counts = CIP_data_training_years.groupby(['YEAR', 'CLINIC']).size().reset_index(name='Count')\n",
    "    counts_by_year = CIP_data_training_years.groupby(['YEAR']).size().reset_index(name='Count')\n",
    "\n",
    "    merged_counts = counts.merge(counts_by_year, on='YEAR', suffixes=('_counts', '_counts_by_year'))\n",
    "\n",
    "    # Calculate the sum of all counts in the counts dataframe\n",
    "    total_counts = counts['Count'].sum()\n",
    "\n",
    "    # Calculate the 'weight' column as Count_counts / total_counts\n",
    "    merged_counts['weight'] = merged_counts['Count_counts'] / total_counts\n",
    "    # Calculate the 'weight' column as Count_counts / rolling sum of the previous 5 years\n",
    "\n",
    "    # Merge the 'weight' column back to the original DataFrame\n",
    "    CIP_data_no_drop = CIP_data_no_drop.merge(merged_counts[['YEAR', 'CLINIC', 'weight']], on=['YEAR', 'CLINIC'], how='left')\n",
    "\n",
    "    test_data, train_data, X_train, y_train, X_test, y_test, cipro_R_prev =  get_test_train_data(CIP_data_no_drop=CIP_data_no_drop, year=year, feature_names=feature_names, years_train=years_train, model_type=model_type)\n",
    "\n",
    "    ## before fitting the model, do hyperparameter tuning\n",
    "    model_nn = KerasClassifier(build_fn=create_mlp_model, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    best_hyperparameters1 = get_best_hyperparameters(model_nn, cv, space, X_train, y_train)\n",
    "    model_nn = create_mlp_model(\n",
    "        activation=best_hyperparameters1['activation'],\n",
    "        alpha=best_hyperparameters1['alpha'],\n",
    "        learning_rate=best_hyperparameters1['learning_rate'],\n",
    "        hidden_layer_sizes=best_hyperparameters1['hidden_layer_sizes']\n",
    "    )\n",
    "\n",
    "    ## fit model w/hyperparameters\n",
    "    model_nn.fit(X_train, y_train, sample_weight=train_data['weight'].values)  # Pass the instance weights\n",
    "\n",
    "    ## now also need to do feature engineering\n",
    "    important_features = get_best_features(feature_names, model_nn, X_train, y_train)\n",
    "\n",
    "    best_features_by_year[model_type].__setitem__(year, important_features) \n",
    "    imporances_all_models[i + indices_for_importance[model_type]] = get_feature_effects(feature_names, important_features, model_nn, X_train, y_train) #want it to be the correct block for each model\n",
    "    imporances_all_models_sd[i + indices_for_importance[model_type]] = get_feature_effects(feature_names, important_features, model_nn, X_train, y_train) #want it to be the correct block for each model\n",
    "\n",
    "    # get new test/train data and hyperparameter tuning round 2\n",
    "    test_data, train_data, X_train, y_train, X_test, y_test, cipro_R_prev =  get_test_train_data(CIP_data_no_drop=CIP_data_no_drop, year=year, feature_names=important_features, years_train=years_train, model_type=model_type)\n",
    "    \n",
    "    best_hyperparameters2 = get_best_hyperparameters(model_nn, cv, space, X_train, y_train)\n",
    "\n",
    "    best_hyperparameters_by_year[model_type].__setitem__(year, best_hyperparameters2) \n",
    "\n",
    "    ## fit model w/hyperparameters \n",
    "    model_nn = create_mlp_model(\n",
    "        activation=best_hyperparameters2['activation'],\n",
    "        alpha=best_hyperparameters2['alpha'],\n",
    "        learning_rate=best_hyperparameters2['learning_rate'],\n",
    "        hidden_layer_sizes=best_hyperparameters2['hidden_layer_sizes']\n",
    "    )\n",
    "\n",
    "    model_nn.fit(X_train, y_train, sample_weight=train_data['weight'].values, verbose=0)  # Pass the instance weights\n",
    "    y_predict_test = model_nn.predict_classes(X_test)\n",
    "    y_predict_proba = model_nn.predict(X_test)\n",
    "\n",
    "    ROC = roc_auc_score(y_test, y_predict_proba)\n",
    "    ROC_by_year[model_type].__setitem__(year, ROC)\n",
    "    i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentiles(iterations, ROC_actual, test_data, model_type,y_test):\n",
    "        bootstrapped_stats = []\n",
    "        for j in range(iterations):\n",
    "            model_name = \"/Users/rem76/Documents/ML_Models/Bootstrap_models_GISP/CIP_bootstrap_no_dev_\" + str(model_type) + \"_\" + str(year) + \"_\" + str(j) + \".sav\" \n",
    "            X_data_name = \"/Users/rem76/Documents/ML_Models/Bootstrap_models_GISP/CIP_bootstrap_X_no_dev_\" + str(model_type) + \"_\" + str(year) + \"_\" + str(j) + \".csv\" \n",
    "            ## don't need to read in weights as the model has already been trained\n",
    "            X_train_bootstrap = pd.read_csv(X_data_name)\n",
    "            model_fit = pickle.load(open(model_name, 'rb'))\n",
    "            X_test_for_bootstrap = test_data[X_train_bootstrap.columns[1:len(X_train_bootstrap.columns)]]\n",
    "            y_bootstrap_predict = model_fit.predict(X_test_for_bootstrap)\n",
    "            ROC_AUC_bootstrap_test_performance = metrics.roc_auc_score(y_test, y_bootstrap_predict) \n",
    "        ### (D) Calculate estimate fo variance  by getting (B) - (D) \n",
    "\n",
    "            difference = ROC_AUC_bootstrap_test_performance - ROC_actual ## according to https://ocw.mit.edu/courses/18-05-introduction-to-probability-and-statistics-spring-2014/resources/mit18_05s14_reading24/\n",
    "\n",
    "            bootstrapped_stats.append({'Difference': difference})\n",
    "\n",
    "\n",
    "        bootstrapped_stats = pd.DataFrame(bootstrapped_stats)\n",
    "    ## Step 3: Get average optimization\n",
    "        alpha = 0.05\n",
    "        #lower_quartile = np.percentile(bootstrapped_stats[\"Difference\"], 2.5)\n",
    "        #upper_quartile = np.percentile(bootstrapped_stats[\"Difference\"], 97.5)\n",
    "        upper_quartile, lower_quartile = ROC_actual - np.percentile(bootstrapped_stats[\"Difference\"], [100 * (1 - alpha / 2.0), 100 * alpha / 2.0])\n",
    "        #upper_quartile = np.percentile(bootstrapped_stats[\"Difference\"], 2.5)\n",
    "        #lower_quartile = np.percentile(bootstrapped_stats[\"Difference\"], 97.5)\n",
    " ## Step 4: Get optimization-corrected performance\n",
    "\n",
    "        return lower_quartile, upper_quartile\n",
    "\n",
    "### now try bootstrapping w/o feature selection\n",
    "iterations = 100\n",
    "## DO NOT SAMPLE THE TARGET DATA\n",
    "def bootstrap_auROC_no_dev(iterations, model, train_data, test_data, y_test, ROC_actual, important_features):\n",
    "      #1. Find apparent model performance\n",
    "    bootstrapped_stats = []\n",
    "    feature_names_with_weight = important_features.copy()\n",
    "    feature_names_with_weight.extend(['weight'])\n",
    "    for i in range(iterations):\n",
    "        #2. (A) Sample all individuals from training data w/replacement\n",
    "\n",
    "          sample_train = train_data.sample(frac = 1, replace=True) ##(a) sample n individuals with replacement\n",
    "          \n",
    "          X_sample_train = sample_train[feature_names_with_weight]\n",
    "          y_sample_train = 1 - sample_train['Susceptible']\n",
    "\n",
    "          if model_type in [1,2]:\n",
    "            X_sample_train, y_sample_train = oversample.fit_resample(X_sample_train,y_sample_train)\n",
    "          weights_train = X_sample_train[\"weight\"]\n",
    "          X_sample_train  = X_sample_train.drop(\"weight\", axis = 1)\n",
    "        #  (B) Predictive model w/o feature selection \n",
    "          X_test_bootstrap = test_data[important_features]\n",
    "          model_fit = model.fit(X_sample_train, y_sample_train, sample_weight = weights_train)\n",
    "\n",
    "          model_name = \"/Users/rem76/Documents/ML_Models/Bootstrap_models_GISP/CIP_bootstrap_no_dev_\" + str(model_type) + \"_\" + str(year) + \"_\" + str(i) + \".sav\" \n",
    "          X_data_name = \"/Users/rem76/Documents/ML_Models/Bootstrap_models_GISP/CIP_bootstrap_X_no_dev_\" + str(model_type) + \"_\" + str(year) + \"_\" + str(i) + \".csv\" \n",
    "          y_data_name = \"/Users/rem76/Documents/ML_Models/Bootstrap_models_GISP/CIP_bootstrap_y_no_dev_\" + str(model_type) + \"_\" + str(year) + \"_\" + str(i) + \".csv\" \n",
    "          weights_data_name = \"/Users/rem76/Documents/ML_Models/Bootstrap_models_GISP/CIP_bootstrap_weights_\" + str(model_type) + \"_\" + str(year) + \"_\" + str(i) + \".csv\" \n",
    "          \n",
    "          weights_train.to_csv(weights_data_name)\n",
    "          X_sample_train.to_csv(X_data_name)\n",
    "          y_sample_train.to_csv(y_data_name)\n",
    "          pickle.dump(model_fit, open(model_name, 'wb'))\n",
    "        #  (C) Performance of predictive model on original sample (i.e. original training population, X_test, with new selected features)\n",
    "          y_bootstrap_predict = model_fit.predict(X_test_bootstrap)\n",
    "          ROC_AUC_bootstrap_test_performance = metrics.roc_auc_score(y_test, y_bootstrap_predict) \n",
    "        ### (D) Calculate estimate fo variance  by getting (B) - (D) \n",
    "\n",
    "          difference = ROC_AUC_bootstrap_test_performance - ROC_actual ## according to https://ocw.mit.edu/courses/18-05-introduction-to-probability-and-statistics-spring-2014/resources/mit18_05s14_reading24/\n",
    "\n",
    "          bootstrapped_stats.append(\n",
    "          {\n",
    "\n",
    "              'Difference': difference#,\n",
    "          }\n",
    "        )\n",
    "\n",
    "\n",
    "    bootstrapped_stats = pd.DataFrame(bootstrapped_stats)\n",
    "    ## Step 3: Get average optimization\n",
    "\n",
    "    #lower_quartile = np.percentile(bootstrapped_stats[\"Difference\"], 2.5)\n",
    "    #upper_quartile = np.percentile(bootstrapped_stats[\"Difference\"], 97.5)\n",
    " ## Step 4: Get optimization-corrected performance\n",
    "    alpha = 0.05 \n",
    "    upper_quartile, lower_quartile = ROC_actual - np.percentile(bootstrapped_stats[\"Difference\"], [100 * (1 - alpha / 2.0), 100 * alpha / 2.0])\n",
    "\n",
    "    return lower_quartile, upper_quartile\n",
    "\n",
    "\n",
    "def bootstrap_auROC_no_dev_tensorflow(iterations, model, train_data, test_data, y_test, ROC_actual, important_features):\n",
    "    # 1. Find apparent model performance\n",
    "    bootstrapped_stats = []\n",
    "    feature_names_with_weight = important_features.copy()\n",
    "    feature_names_with_weight.extend(['weight'])\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # 2. (A) Sample all individuals from training data w/replacement\n",
    "        sample_train = train_data.sample(frac = 1, replace=True)\n",
    "\n",
    "        X_sample_train = sample_train[feature_names_with_weight]\n",
    "        y_sample_train = 1 - sample_train['Susceptible']\n",
    "\n",
    "        if model_type in [1, 2]:\n",
    "            X_sample_train, y_sample_train = oversample.fit_resample(X_sample_train, y_sample_train)\n",
    "\n",
    "        weights_train = X_sample_train[\"weight\"]\n",
    "        X_sample_train = X_sample_train.drop(\"weight\", axis=1)\n",
    "\n",
    "        # (B) Predictive model w/o feature selection\n",
    "        X_test_bootstrap = test_data[important_features]\n",
    "\n",
    "        model.fit(X_sample_train, y_sample_train, sample_weight=weights_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "        model_name = f\"/Users/rem76/Documents/ML_Models/Bootstrap_models_GISP/CIP_bootstrap_no_dev_{model_type}_{year}_{i}.sav\"\n",
    "        X_data_name = f\"/Users/rem76/Documents/ML_Models/Bootstrap_models_GISP/CIP_bootstrap_X_no_dev_{model_type}_{year}_{i}.csv\"\n",
    "        y_data_name = f\"/Users/rem76/Documents/ML_Models/Bootstrap_models_GISP/CIP_bootstrap_y_no_dev_{model_type}_{year}_{i}.csv\"\n",
    "        weights_data_name = f\"/Users/rem76/Documents/ML_Models/Bootstrap_models_GISP/CIP_bootstrap_weights_{model_type}_{year}_{i}.csv\"\n",
    "\n",
    "        weights_train.to_csv(weights_data_name)\n",
    "        X_sample_train.to_csv(X_data_name)\n",
    "        y_sample_train.to_csv(y_data_name)\n",
    "        pickle.dump(model_nn, open(model_name, 'wb'))\n",
    "\n",
    "        # (C) Performance of predictive model on original sample (i.e. original training population, X_test, with new selected features)\n",
    "        y_bootstrap_predict = model.predict_classes(X_test_bootstrap)\n",
    "        ROC_AUC_bootstrap_test_performance = roc_auc_score(y_test, y_bootstrap_predict)\n",
    "\n",
    "        # (D) Calculate estimate of variance by getting (B) - (C)\n",
    "        difference = ROC_AUC_bootstrap_test_performance - ROC_actual\n",
    "\n",
    "        bootstrapped_stats.append({\n",
    "            'Difference': difference\n",
    "        })\n",
    "\n",
    "    bootstrapped_stats = pd.DataFrame(bootstrapped_stats)\n",
    "\n",
    "    # Step 3: Get average optimization\n",
    "    lower_quartile, upper_quartile = np.percentile(bootstrapped_stats[\"Difference\"], [2.5, 97.5])\n",
    "\n",
    "    # Step 4: Get optimization-corrected performance\n",
    "    alpha = 0.05\n",
    "    upper_quartile, lower_quartile = ROC_actual - np.percentile(bootstrapped_stats[\"Difference\"], [100 * (1 - alpha / 2.0), 100 * alpha / 2.0])\n",
    "\n",
    "    return lower_quartile, upper_quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### quartile differece by year \n",
    "lower_quartile_by_year_rf = {}\n",
    "lower_quartile_by_year_lr = {}\n",
    "lower_quartile_by_year_nn = {}\n",
    "\n",
    "lower_quartile_by_year = [lower_quartile_by_year_lr, lower_quartile_by_year_rf, lower_quartile_by_year_nn]\n",
    "\n",
    "upper_quartile_by_year_rf = {}\n",
    "upper_quartile_by_year_lr = {}\n",
    "upper_quartile_by_year_nn = {}\n",
    "\n",
    "upper_quartile_by_year = [upper_quartile_by_year_lr, upper_quartile_by_year_rf, upper_quartile_by_year_nn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIP_data_no_drop = CIP_data_no_drop.drop('weight_y', axis = 1)\n",
    "CIP_data_no_drop = CIP_data_no_drop.drop('weight_x', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "Oversample\n",
      "2006\n",
      "Oversample\n",
      "2007\n",
      "Oversample\n",
      "2008\n",
      "Oversample\n",
      "2009\n",
      "Oversample\n",
      "2010\n",
      "Oversample\n"
     ]
    }
   ],
   "source": [
    "# RF bootstrapping \n",
    "model_rf = RandomForestClassifier(n_estimators = 171, min_samples_split = 1, min_samples_leaf=1, max_features = 'sqrt', max_depth = 89, random_state = 10)\n",
    "\n",
    "i = 0\n",
    "for year in test_years: \n",
    "    print(year)\n",
    "    model_type = 1\n",
    "    years_train = np.array(range(year - 5, year))\n",
    "\n",
    "    CIP_data_training_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin(years_train)]\n",
    "    CIP_data_testing_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin([year])]\n",
    "    # first do for all clinics \n",
    "    counts = CIP_data_training_years.groupby(['YEAR', 'CLINIC']).size().reset_index(name='Count')\n",
    "    counts_by_year = CIP_data_training_years.groupby(['YEAR']).size().reset_index(name='Count')\n",
    "\n",
    "    merged_counts = counts.merge(counts_by_year, on='YEAR', suffixes=('_counts', '_counts_by_year'))\n",
    "\n",
    "    # Calculate the sum of all counts in the counts dataframe\n",
    "    total_counts = counts['Count'].sum()\n",
    "\n",
    "    # Calculate the 'weight' column as Count_counts / total_counts\n",
    "    merged_counts['weight'] = merged_counts['Count_counts'] / total_counts\n",
    "    # Calculate the 'weight' column as Count_counts / rolling sum of the previous 5 years\n",
    "\n",
    "    # Merge the 'weight' column back to the original DataFrame\n",
    "    CIP_data_no_drop = CIP_data_no_drop.merge(merged_counts[['YEAR', 'CLINIC', 'weight']], on=['YEAR', 'CLINIC'], how='left')\n",
    "    model_rf = RandomForestClassifier(n_estimators = best_hyperparameters_by_year[model_type][year]['n_estimators'], min_samples_split = best_hyperparameters_by_year[model_type][year]['min_samples_split'], min_samples_leaf=best_hyperparameters_by_year[model_type][year]['min_samples_leaf'], max_features = 'sqrt', max_depth = best_hyperparameters_by_year[model_type][year]['max_depth'], random_state = 10)\n",
    "\n",
    "    test_data, train_data, X_train, y_train, X_test, y_test, cipro_R_prev, sample_weights  =  get_test_train_data(CIP_data_no_drop = CIP_data_no_drop, year = year, feature_names = best_features_by_year[model_type][year],years_train = years_train, model_type = model_type)\n",
    "       ## fit model w/hyperparameters \n",
    "   \n",
    "    model_name = \"CIP_rf_\" + str(year) + \".sav\" \n",
    "    #model_fit_train = pickle.load(open(model_name, 'rb'))\n",
    "    model_fit_train = model_rf.fit(X_train, y_train)\n",
    "    y_predict_test = model_fit_train.predict(X_test)\n",
    "    y_predict_proba = model_fit_train.predict_proba(X_test)\n",
    "    model_name = \"CIP_rf_\" + str(year) + \".sav\" \n",
    "    pickle.dump(model_rf, open(model_name, 'wb'))\n",
    "    ROC= metrics.roc_auc_score(y_test, y_predict_test)\n",
    "\n",
    "    #lower_quartile, upper_quartile = bootstrap_auROC(iterations, model_rf, train_data, test_data, y_test, ROC_actual = ROC_by_year_rf[year])\n",
    "    lower_quartile, upper_quartile = bootstrap_auROC_no_dev(iterations, model_rf, train_data, test_data, y_test, ROC_actual = ROC_by_year[model_type][year], important_features = best_features_by_year[model_type][year])\n",
    "    CIP_data_no_drop = CIP_data_no_drop.drop('weight', axis = 1)\n",
    "\n",
    "    lower_quartile_by_year[model_type].__setitem__(year, lower_quartile)\n",
    "    upper_quartile_by_year[model_type].__setitem__(year, upper_quartile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just LR\n",
    "model_lr = LogisticRegression(class_weight = 'balanced', max_iter=4000, solver = \"lbfgs\", C = 0.27, penalty = 'l2')\n",
    "\n",
    "i = 0\n",
    "for year in test_years: \n",
    "    print(year)\n",
    "    model_type = 0\n",
    "    years_train = np.array(range(year - 5, year))\n",
    "\n",
    "    CIP_data_training_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin(years_train)]\n",
    "    CIP_data_testing_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin([year])]\n",
    "    # first do for all clinics \n",
    "    counts = CIP_data_training_years.groupby(['YEAR', 'CLINIC']).size().reset_index(name='Count')\n",
    "    counts_by_year = CIP_data_training_years.groupby(['YEAR']).size().reset_index(name='Count')\n",
    "\n",
    "    merged_counts = counts.merge(counts_by_year, on='YEAR', suffixes=('_counts', '_counts_by_year'))\n",
    "\n",
    "    # Calculate the sum of all counts in the counts dataframe\n",
    "    total_counts = counts['Count'].sum()\n",
    "\n",
    "    # Calculate the 'weight' column as Count_counts / total_counts\n",
    "    merged_counts['weight'] = merged_counts['Count_counts'] / total_counts\n",
    "    # Calculate the 'weight' column as Count_counts / rolling sum of the previous 5 years\n",
    "\n",
    "    # Merge the 'weight' column back to the original DataFrame\n",
    "    CIP_data_no_drop = CIP_data_no_drop.merge(merged_counts[['YEAR', 'CLINIC', 'weight']], on=['YEAR', 'CLINIC'], how='left')\n",
    " \n",
    "    model_lr = LogisticRegression(class_weight = 'balanced', max_iter=4000, solver = best_hyperparameters_by_year[model_type][year]['solver'], C = best_hyperparameters_by_year[model_type][year]['C'], penalty = best_hyperparameters_by_year[model_type][year]['penalty'])\n",
    "\n",
    "    test_data, train_data, X_train, y_train, X_test, y_test, cipro_R_prev  =  get_test_train_data(CIP_data_no_drop = CIP_data_no_drop, year = year, feature_names = best_features_by_year[model_type][year],years_train = years_train, model_type = model_type)\n",
    "       ## fit model w/hyperparameters \n",
    "    model_name = \"CIP_lr_\" + str(year) + \".sav\" \n",
    "    #model_fit_train = pickle.load(open(model_name, 'rb'))\n",
    "    model_fit_train = model_lr.fit(X_train, y_train)\n",
    "    y_predict_test = model_fit_train.predict(X_test)\n",
    "    y_predict_proba = model_fit_train.predict_proba(X_test)\n",
    "    pickle.dump(model_lr, open(model_name, 'wb'))\n",
    "    #ROC= metrics.roc_auc_score(y_test, y_predict_test)\n",
    "    #lower_quartile, upper_quartile = bootstrap_auROC(iterations, model_lr, train_data, test_data, y_test, ROC_actual = ROC_by_year_lr[year])\n",
    "    lower_quartile, upper_quartile = bootstrap_auROC_no_dev(iterations, model_lr, train_data, test_data, y_test, ROC_actual = ROC_by_year[model_type][year], important_features = best_features_by_year[model_type][year])\n",
    "    CIP_data_no_drop = CIP_data_no_drop.drop('weight', axis = 1)\n",
    "    lower_quartile_by_year[model_type].__setitem__(year, lower_quartile)\n",
    "    upper_quartile_by_year[model_type].__setitem__(year, upper_quartile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['weight'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_data, train_data, X_train, y_train, X_test, y_test, cipro_R_prev, sample_weights  \u001b[39m=\u001b[39m  get_test_train_data(CIP_data_no_drop \u001b[39m=\u001b[39;49m CIP_data_no_drop, year \u001b[39m=\u001b[39;49m year, feature_names \u001b[39m=\u001b[39;49m best_features_by_year[model_type][year],years_train \u001b[39m=\u001b[39;49m years_train, model_type \u001b[39m=\u001b[39;49m model_type)\n",
      "Cell \u001b[0;32mIn[7], line 126\u001b[0m, in \u001b[0;36mget_test_train_data\u001b[0;34m(CIP_data_no_drop, year, feature_names, years_train, model_type)\u001b[0m\n\u001b[1;32m    124\u001b[0m feature_names_with_weight\u001b[39m.\u001b[39mextend([\u001b[39m'\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    125\u001b[0m train_data \u001b[39m=\u001b[39m CIP_data_no_drop\u001b[39m.\u001b[39mloc[CIP_data_no_drop[\u001b[39m\"\u001b[39m\u001b[39mYEAR\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39misin(years_train)]\n\u001b[0;32m--> 126\u001b[0m X_train \u001b[39m=\u001b[39m train_data[feature_names_with_weight]  \u001b[39m# need to consider all columns BEFORE feature engineering\u001b[39;00m\n\u001b[1;32m    127\u001b[0m y_train \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m train_data[\u001b[39m\"\u001b[39m\u001b[39mSusceptible\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    128\u001b[0m \u001b[39m# test\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/pandas/core/frame.py:3811\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3810\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3811\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3813\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/pandas/core/indexes/base.py:6113\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6111\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6113\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6115\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6117\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/pandas/core/indexes/base.py:6176\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6175\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6176\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['weight'] not in index\""
     ]
    }
   ],
   "source": [
    "test_data, train_data, X_train, y_train, X_test, y_test, cipro_R_prev, sample_weights  =  get_test_train_data(CIP_data_no_drop = CIP_data_no_drop, year = year, feature_names = best_features_by_year[model_type][year],years_train = years_train, model_type = model_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Graph 1: auROC by year 2005-2010, trained on previous 5 years' data, for nn, rf and lr with intervals\n",
    "fig, axs = plt.subplots(figsize=(7.5, 7.5), facecolor='w', edgecolor='k', sharex = 'all', sharey = 'all')\n",
    "years = np.array(range(2005, 2011))\n",
    "axs.tick_params(axis='both', which='major', labelsize=18)\n",
    "axs.set_xticks(np.array(range(2005, 2011)))\n",
    "#axs.set_xticks([2005, 2007, 2010])\n",
    "\n",
    "axs.plot(years, ROC_by_year[2].values(),linewidth = 2, label = \"Neural network\", color = \"#edae49\")\n",
    "axs.fill_between(years, lower_quartile_by_year[2].values(), upper_quartile_by_year[2].values(), color = \"#edae49\", alpha = 0.3)\n",
    "\n",
    "axs.plot(years, ROC_by_year[0].values(),linewidth = 2, label = \"Logistic regression\", color = \"#d1495b\")\n",
    "axs.fill_between(years, lower_quartile_by_year[0].values(), upper_quartile_by_year[0].values(), color = \"#d1495b\", alpha = 0.3)\n",
    "\n",
    "axs.plot(years, ROC_by_year[1].values(),linewidth = 2, label = \"Random forest\", color = \"#00798c\")\n",
    "axs.fill_between(years, lower_quartile_by_year[1].values(), upper_quartile_by_year[1].values(), color = \"#00798c\", alpha = 0.3)\n",
    "\n",
    "axs.set_ylabel(\"auROC\", fontsize = 18, **hfont)\n",
    "axs.set_xlabel(\"Target year\",  fontsize = 18,**hfont)\n",
    "axs.set_ylim([0.5,1])\n",
    "axs.legend(prop={'size':14})\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GISP_init",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37b4cc77837642ee25c4eb6578aebe03e17eb3bb59efdde49edbbc888dbc418f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
