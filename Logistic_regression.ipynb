{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'CLINIC', 'YEAR', 'GENDERSP',\n",
      "       'Susceptible', 'MSMW', 'MSW', 'Oth/Unk/Missing', 'REGION', 'Northeast',\n",
      "       'Southeast', 'Southwest', 'West', 'PREV_REGION', 'PREV_CLINIC'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "## read data \n",
    "CIP_data = pd.read_csv(\"CIP_data_encode_prev.csv\")\n",
    "CIP_data.head()\n",
    "print(CIP_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72996879639425\n",
      "0.7201325178334779\n",
      "ACCURACY OF THE MODEL:  0.72996879639425\n",
      "0.706282979506688\n",
      "0.7339820561602678\n"
     ]
    }
   ],
   "source": [
    "### Step 1: create model and calculate apparent performance metric of interest (P)\n",
    "CIP_data.columns\n",
    "X = CIP_data[['MSMW', 'MSW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West', 'PREV_REGION', 'PREV_CLINIC']]\n",
    "y = CIP_data['Susceptible']\n",
    "#print(X[\"PREV_CLINIC\"].isnull().values.any())\n",
    "model = LogisticRegression(class_weight = 'balanced', max_iter=1000)\n",
    "model_fit = model.fit(X, y)\n",
    "\n",
    "#print(model_fit.coef_)\n",
    "print(model_fit.score(X,y)) # 0.72996879639425\n",
    "\n",
    "\n",
    "y_predict = model_fit.predict(X)\n",
    "\n",
    "ROC_AUC_logistic = metrics.roc_auc_score(y, y_predict) #0.679905016859595\n",
    "print(ROC_AUC_logistic) # 0.7201325178334779\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y, y_predict)) ## ACCURACY OF THE MODEL:  0.72996879639425\n",
    "\n",
    "\n",
    "## this is \"P\" from S4 https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000059 (step 1)\n",
    "\n",
    "## add in confusion matrix \n",
    "tn, fp, fn, tp = confusion_matrix(y, y_predict).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "print(specificity) #0.706282979506688\n",
    "\n",
    "print(sensitivity )#0.7339820561602678\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Bootstrapping validation \n",
    "n_iterations = 10\n",
    "bootstrapped_stats = pd.DataFrame()\n",
    "bootstrapped_stats = []\n",
    "## the test and train data for the bootstrapping will be the same, as above\n",
    "\n",
    "train = resample(CIP_data, replace=True, n_samples=len(CIP_data))\n",
    "\n",
    "train.head()\n",
    "\n",
    "X_train = CIP_data[['MSMW', 'MSW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West', 'PREV_REGION', 'PREV_CLINIC']]\n",
    "y_train = CIP_data['Susceptible']\n",
    "\n",
    "model_train = LogisticRegression(class_weight = 'balanced', max_iter = 500)\n",
    "model_train = model_train.fit(X_train, y_train)\n",
    "\n",
    "#print(model.coef_)\n",
    "#print(model.score(X,y)) # 0.56\n",
    "\n",
    "y_predict = model_train.predict(X_train)\n",
    "\n",
    "ROC_AUC_logistic_train = metrics.roc_auc_score(y_train, y_predict)\n",
    "\n",
    "for i in range(n_iterations):\n",
    "       sample = resample(CIP_data, replace=True, n_samples=len(CIP_data)) ##(a) sample n individuals with replacement\n",
    "\n",
    "       X_sample  = sample[['MSMW', 'MSW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West', 'PREV_REGION', 'PREV_CLINIC']]\n",
    "\n",
    "       y_sample = sample['Susceptible']\n",
    "\n",
    "       model = LogisticRegression(class_weight = 'balanced', max_iter = 500) #calculate APPARENT performance - ROC\n",
    "       model_sample = model.fit(X_sample, y_sample)\n",
    "       y_predict_sample = model_sample.predict(X_sample) \n",
    "       ROC_AUC_logistic_sample = metrics.roc_auc_score(y_sample, y_predict_sample)\n",
    "       tn_sample, fp_sample, fn_sample, tp_sample = confusion_matrix(y_sample, y_predict_sample).ravel()\n",
    "       specificity_sample = tn_sample / (tn_sample+fp_sample)\n",
    "       sensitivity_sample = tp_sample / (tp_sample + fn_sample)\n",
    "\n",
    "\n",
    "       y_test = model_sample.predict(X) #see how model trained on sample data performns on original data  \n",
    "       ROC_AUC_logistic_test = metrics.roc_auc_score(y_sample, y_test) \n",
    "       tn_test, fp_test, fn_test, tp_test = confusion_matrix(y, y_test).ravel() ##confusion matrix between predicted data from original data and the actual original data\n",
    "       specificity_test = tn_test / (tn_test+fp_test)\n",
    "       sensitivity_test = tp_test / (tp_test + fn_test)\n",
    "\n",
    "\n",
    "       optomisation = ROC_AUC_logistic_sample - ROC_AUC_logistic_test #optimisation\n",
    "       optomisation_specificity = specificity_sample - specificity_test #optimisation\n",
    "       optomisation_sensitivity = sensitivity_sample - sensitivity_test #optimisation\n",
    "\n",
    "       bootstrapped_stats.append(\n",
    "        {\n",
    "            'Sample ROC': ROC_AUC_logistic_sample,\n",
    "            'Test ROC': ROC_AUC_logistic_test,\n",
    "            'Optimisation': optomisation,\n",
    "            'Sensitivity_sample': sensitivity,\n",
    "            'Specificity_sample':specificity, \n",
    "            'Optimisation_sensitivity': optomisation_sensitivity,\n",
    "            'Optimisation_specificity': optomisation_specificity\n",
    "        }\n",
    "       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498543195812248\n",
      "0.7159517777118338 0.27132622251735494\n",
      "0.7343160767808556 0.7054723319506329\n"
     ]
    }
   ],
   "source": [
    "bootstrapped_stats = pd.DataFrame(bootstrapped_stats)\n",
    "#print(bootstrapped_stats)\n",
    "## Step 3: Get average optimization\n",
    "\n",
    "average_optimisation = bootstrapped_stats[\"Optimisation\"].mean() \n",
    "\n",
    "## Step 4: Get optimization-corrected performance\n",
    "\n",
    "optimization_corrected_performance = ROC_AUC_logistic - average_optimisation ##\n",
    "\n",
    "print(optimization_corrected_performance)\n",
    "\n",
    "## get CI \n",
    "\n",
    "#Bootstrap_CI = bootstrapped_stats[\"Optimisation\"].quantile(q = 0.975)\n",
    "conf_interval = np.percentile(bootstrapped_stats[\"Optimisation\"],[2.5,97.5])\n",
    "Upper_bootstrap_CI = optimization_corrected_performance +conf_interval[0]\n",
    "Lower_bootstrap_CI = optimization_corrected_performance - conf_interval[1]\n",
    "\n",
    "print(Upper_bootstrap_CI, Lower_bootstrap_CI)\n",
    "\n",
    "#0.49942646634516624\n",
    "#0.6772986683407078 0.3152392553329397\n",
    "\n",
    "## sensitivity and specificity \n",
    "average_optimised_sensitivity = bootstrapped_stats[\"Optimisation_sensitivity\"].mean()  #0.6417965394526935\n",
    "average_optimised_specificity = bootstrapped_stats[\"Optimisation_specificity\"].mean()   #0.7180134942664962 \n",
    "\n",
    "optimization_corrected_performance_sensitivity = sensitivity - average_optimised_sensitivity ## 0.7178314223295834\n",
    "\n",
    "optimization_corrected_performance_specificity = specificity - average_optimised_specificity ## 0.640672271758783\n",
    "\n",
    "print(optimization_corrected_performance_sensitivity, optimization_corrected_performance_specificity)\n",
    "\n",
    "#so both are low..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try L1 regularization \n",
    "from sklearn.linear_model import Lasso\n",
    "X = CIP_data[['MSMW', 'MSW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West', 'PREV_REGION', 'PREV_CLINIC']]\n",
    "\n",
    "y = CIP_data['Susceptible']\n",
    "\n",
    "#lasso = Lasso(alpha = 0.1)\n",
    "#model = lasso.fit(X, y)\n",
    "#print(model_fit.coef_)\n",
    "#print(model_fit.score(X,y)) # 0.56\n",
    "\n",
    "#y_predict = lasso.predict(X)\n",
    "\n",
    "#ROC_AUC_logistic = metrics.roc_auc_score(y, y_predict)\n",
    "#print(ROC_AUC_logistic) # 0.635\n",
    "#print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y, y_predict)) ## but get model accuracy of 0.5620116102305155\n",
    "\n",
    "\n",
    "model = LogisticRegression(C=0.01, class_weight = 'balanced')\n",
    "model_fit = model.fit(X, y)\n",
    "y_predict = model_fit.predict(X)\n",
    "\n",
    "ROC_AUC_logistic = metrics.roc_auc_score(y, y_predict)\n",
    "print(ROC_AUC_logistic)\n",
    "\n",
    "\n",
    "bootstrapped_stats = []\n",
    "n_iterations = 20\n",
    "\n",
    "for i in range(n_iterations):\n",
    "       sample = resample(CIP_data, replace=True, n_samples=len(CIP_data)) ##(a) sample n individuals with replacement\n",
    "\n",
    "       X_sample  = sample[['MSMW', 'MSW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West', 'PREV_REGION', 'PREV_CLINIC']]\n",
    "\n",
    "       y_sample = sample['Susceptible']\n",
    "\n",
    "       model = LogisticRegression(C=0.001, class_weight = 'balanced') #calculate APPARENT performance - ROC\n",
    "       model_sample = model.fit(X_sample, y_sample)\n",
    "       y_predict_sample = model_sample.predict(X_sample) \n",
    "       ROC_AUC_logistic_sample = metrics.roc_auc_score(y_sample, y_predict_sample)\n",
    "\n",
    "       y_test = model_sample.predict(X) #performance on original data  \n",
    "       ROC_AUC_logistic_test = metrics.roc_auc_score(y_sample, y_test)\n",
    "\n",
    "       optomisation = ROC_AUC_logistic_sample - ROC_AUC_logistic_test #optimisation\n",
    "\n",
    "       bootstrapped_stats.append(\n",
    "        {\n",
    "            'Sample ROC': ROC_AUC_logistic_sample,\n",
    "            'Test ROC': ROC_AUC_logistic_test,\n",
    "            'Optimisation': optomisation\n",
    "        }\n",
    "       )\n",
    "\n",
    "bootstrapped_stats = pd.DataFrame(bootstrapped_stats)\n",
    "#print(bootstrapped_stats)\n",
    "## Step 3: Get average optimization\n",
    "\n",
    "average_optimisation = bootstrapped_stats[\"Optimisation\"].mean() \n",
    "\n",
    "## Step 4: Get optimization-corrected performance\n",
    "\n",
    "optimization_corrected_performance = ROC_AUC_logistic - average_optimisation ##\n",
    "\n",
    "print(optimization_corrected_performance)\n",
    "\n",
    "## get CI \n",
    "\n",
    "#Bootstrap_CI = bootstrapped_stats[\"Optimisation\"].quantile(q = 0.975)\n",
    "conf_interval = np.percentile(bootstrapped_stats[\"Optimisation\"],[2.5,97.5])\n",
    "Upper_bootstrap_CI = optimization_corrected_performance +conf_interval[0]\n",
    "Lower_bootstrap_CI = optimization_corrected_performance - conf_interval[1]\n",
    "\n",
    "print(Upper_bootstrap_CI, Lower_bootstrap_CI)\n",
    "\n",
    "\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "1800 fits failed out of a total of 3000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "390 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "390 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "360 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "210 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'C' parameter of LogisticRegression must be a float in the range (0, inf]. Got 0.0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/rachelmurray-watson/opt/anaconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.73386112        nan        nan        nan        nan\n",
      "        nan        nan 0.73384599        nan        nan        nan\n",
      " 0.73282771        nan        nan        nan 0.73371166 0.73387081\n",
      " 0.73363142        nan 0.73388633        nan        nan 0.73388898\n",
      "        nan 0.73377403 0.73377808 0.73379888        nan 0.73376491\n",
      "        nan 0.73384177 0.73376869 0.73384824        nan 0.73388664\n",
      "        nan 0.73373399 0.73382672        nan        nan        nan\n",
      " 0.73378786        nan 0.73377476        nan        nan        nan\n",
      "        nan        nan 0.73379151        nan        nan        nan\n",
      " 0.73371745 0.73384904        nan        nan        nan 0.733849\n",
      " 0.73388974        nan        nan 0.73389111        nan        nan\n",
      " 0.73371666 0.73388796        nan        nan 0.73382578        nan\n",
      "        nan        nan        nan        nan        nan 0.73385148\n",
      " 0.73380443 0.73372364        nan        nan        nan 0.73389379\n",
      "        nan        nan        nan 0.73389142 0.73381405 0.73377439\n",
      "        nan 0.73384959        nan        nan        nan        nan\n",
      " 0.73378525 0.73382071        nan 0.73386515]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.733893787482822\n",
      "Best Hyperparameters: {'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.9500000000000001}\n"
     ]
    }
   ],
   "source": [
    "## Random search https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['l1', 'l2', 'elasticnet']\n",
    "space['C'] = np.arange(0, 1, 0.05)#loguniform(1e-5, 100)\n",
    "\n",
    "model = LogisticRegression(class_weight = 'balanced', max_iter = 500)\n",
    "model_fit = model.fit(X, y)\n",
    "\n",
    "search = RandomizedSearchCV(model, space, n_iter=100, scoring='roc_auc', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X, y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "#Best Score: 0.7078653885719192\n",
    "#Best Hyperparameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.1}\n",
    "#Best Hyperparameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.05}\n",
    "#Best Score: 0.733893787482822\n",
    "#Best Hyperparameters: {'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.9500000000000001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid search from above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "model = LogisticRegression(class_weight = 'balanced')\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "\n",
    "result = search.fit(X, y)\n",
    "print('Best Hyperparameters: %s' % result.best_params_) #Best Hyperparameters: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Hyperparameters: %s' % result.best_params_) #Best Hyperparameters: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.679905016859595\n",
      "ACCURACY OF THE MODEL:  0.7069705832673998\n",
      "    Sample ROC  Test ROC  Optimisation\n",
      "0     0.676928  0.502300      0.174628\n",
      "1     0.681349  0.499890      0.181459\n",
      "2     0.682233  0.499565      0.182668\n",
      "3     0.679573  0.499934      0.179639\n",
      "4     0.678026  0.499540      0.178486\n",
      "..         ...       ...           ...\n",
      "95    0.681790  0.494846      0.186944\n",
      "96    0.680793  0.499707      0.181086\n",
      "97    0.681081  0.498316      0.182765\n",
      "98    0.682734  0.500297      0.182438\n",
      "99    0.679882  0.500716      0.179166\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "0.5001378786356426\n",
      "0.6745810201109699 0.31370439675223116\n"
     ]
    }
   ],
   "source": [
    "####### repeat steps 1 - 4 with new hyperparameters\n",
    "#Best Hyperparameters: {'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.9500000000000001}\n",
    "### Step 1: create model and calculate apparent performance metric of interest (P)\n",
    "X_sample  = sample[['MSMW', 'MSW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West', 'PREV_REGION', 'PREV_CLINIC']]\n",
    "\n",
    "y_sample = sample['Susceptible']\n",
    "\n",
    "model = LogisticRegression(penalty = 'l2', C= 0.95, solver ='lbfgs', class_weight = 'balanced', max_iter = 500)\n",
    "model_fit = model.fit(X, y)\n",
    "\n",
    "#print(model_fit.coef_)\n",
    "#print(model_fit.score(X,y)) # 0.56\n",
    "\n",
    "y_predict = model_fit.predict(X)\n",
    "\n",
    "ROC_AUC_logistic = metrics.roc_auc_score(y, y_predict)\n",
    "print(ROC_AUC_logistic) #0.7275951887773698\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y, y_predict)) ## but get model accuracy of 0.65511978853664\n",
    "\n",
    "## this is \"P\" from S4 https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000059 (step 1)\n",
    "\n",
    "\n",
    "## Step 2: Bootstrapping validation \n",
    "n_iterations = 100\n",
    "bootstrapped_stats = []\n",
    "## the test and train data for the bootstrapping will be the same, as above\n",
    "\n",
    "for i in range(n_iterations):\n",
    "       sample = resample(CIP_data, replace=True, n_samples=len(CIP_data)) ##(a) sample n individuals with replacement\n",
    "\n",
    "       X_sample  = sample[['MSMW', 'MSW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West', 'PREV_REGION', 'PREV_CLINIC']]\n",
    "\n",
    "       y_sample = sample['Susceptible']\n",
    "\n",
    "       model = LogisticRegression(penalty = 'l2', C= 0.95, solver ='lbfgs', class_weight = 'balanced', max_iter = 500) #calculate APPARENT performance - ROC\n",
    "       model_sample = model.fit(X_sample, y_sample)\n",
    "       y_predict_sample = model_sample.predict(X_sample) \n",
    "       ROC_AUC_logistic_sample = metrics.roc_auc_score(y_sample, y_predict_sample)\n",
    "\n",
    "       y_test = model_sample.predict(X) #performance on original data  \n",
    "       ROC_AUC_logistic_test = metrics.roc_auc_score(y_sample, y_test)\n",
    "\n",
    "       optomisation = ROC_AUC_logistic_sample - ROC_AUC_logistic_test #optimisation\n",
    "\n",
    "       bootstrapped_stats.append(\n",
    "        {\n",
    "            'Sample ROC': ROC_AUC_logistic_sample,\n",
    "            'Test ROC': ROC_AUC_logistic_test,\n",
    "            'Optimisation': optomisation\n",
    "        }\n",
    "       )\n",
    "\n",
    "\n",
    "bootstrapped_stats = pd.DataFrame(bootstrapped_stats)\n",
    "print(bootstrapped_stats)\n",
    "## Step 3: Get average optimization\n",
    "\n",
    "average_optimisation = bootstrapped_stats[\"Optimisation\"].mean() \n",
    "\n",
    "## Step 4: Get optimization-corrected performance\n",
    "\n",
    "optimization_corrected_performance = ROC_AUC_logistic - average_optimisation ##\n",
    "\n",
    "print(optimization_corrected_performance)\n",
    "\n",
    "## get CI \n",
    "\n",
    "#Bootstrap_CI = bootstrapped_stats[\"Optimisation\"].quantile(q = 0.975)\n",
    "conf_interval = np.percentile(bootstrapped_stats[\"Optimisation\"],[2.5,97.5])\n",
    "Upper_bootstrap_CI = optimization_corrected_performance +conf_interval[0]\n",
    "Lower_bootstrap_CI = optimization_corrected_performance - conf_interval[1]\n",
    "\n",
    "print(Upper_bootstrap_CI, Lower_bootstrap_CI)\n",
    "\n",
    "#0.5001378786356426\n",
    "#0.6745810201109699 0.31370439675223116"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GISP_init",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37b4cc77837642ee25c4eb6578aebe03e17eb3bb59efdde49edbbc888dbc418f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
