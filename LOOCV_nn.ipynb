{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', 'CLINIC', 'YEAR',\n",
      "       'GENDERSP', 'Susceptible', 'MSM', 'MSMW', 'MSW', 'Oth/Unk/Missing',\n",
      "       'REGION', 'Midwest', 'Northeast', 'Southeast', 'Southwest', 'West',\n",
      "       'PREV_REGION', 'PREV_CLINIC', 'DELTA_REGION'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#%reset\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import eli5\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import loguniform\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from eli5.sklearn import PermutationImportance\n",
    "## read data \n",
    "CIP_data = pd.read_csv(\"CIP_data_encode_prev.csv\")\n",
    "CIP_data_no_drop = pd.read_csv(\"CIP_data_encode_prev_not_dropped.csv\")\n",
    "print(CIP_data_no_drop.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALB\n",
      "0.0728476821192053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m X_test, y_test \u001b[39m=\u001b[39m oversample\u001b[39m.\u001b[39mfit_resample(X_test,y_test)\n\u001b[1;32m     33\u001b[0m \u001b[39m# test \u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m model_fit_train \u001b[39m=\u001b[39m model_nn\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     35\u001b[0m y_predict_test \u001b[39m=\u001b[39m model_fit_train\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     36\u001b[0m y_predict_proba \u001b[39m=\u001b[39m model_fit_train\u001b[39m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:742\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \n\u001b[1;32m    726\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[39m    Returns a trained MLP model.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 742\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, incremental\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:479\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39m# Run the LBFGS solver\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msolver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 479\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_lbfgs(\n\u001b[1;32m    480\u001b[0m         X, y, activations, deltas, coef_grads, intercept_grads, layer_units\n\u001b[1;32m    481\u001b[0m     )\n\u001b[1;32m    483\u001b[0m \u001b[39m# validate parameter weights\u001b[39;00m\n\u001b[1;32m    484\u001b[0m weights \u001b[39m=\u001b[39m chain(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoefs_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercepts_)\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:523\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit_lbfgs\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    521\u001b[0m     iprint \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m--> 523\u001b[0m opt_res \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49moptimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[1;32m    524\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loss_grad_lbfgs,\n\u001b[1;32m    525\u001b[0m     packed_coef_inter,\n\u001b[1;32m    526\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    527\u001b[0m     jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    528\u001b[0m     options\u001b[39m=\u001b[39;49m{\n\u001b[1;32m    529\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmaxfun\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_fun,\n\u001b[1;32m    530\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    531\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39miprint\u001b[39;49m\u001b[39m\"\u001b[39;49m: iprint,\n\u001b[1;32m    532\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mgtol\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m    533\u001b[0m     },\n\u001b[1;32m    534\u001b[0m     args\u001b[39m=\u001b[39;49m(X, y, activations, deltas, coef_grads, intercept_grads),\n\u001b[1;32m    535\u001b[0m )\n\u001b[1;32m    536\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m _check_optimize_result(\u001b[39m\"\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m\"\u001b[39m, opt_res, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter)\n\u001b[1;32m    537\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_ \u001b[39m=\u001b[39m opt_res\u001b[39m.\u001b[39mfun\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/scipy/optimize/_minimize.py:699\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    696\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    697\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    698\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 699\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    700\u001b[0m                            callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    701\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    702\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    703\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:360\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    354\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    355\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    356\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    361\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:272\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._loss_grad_lbfgs\u001b[0;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the MLP loss function and its corresponding derivatives\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39mwith respect to the different parameters given in the initialization.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mgrad : array-like, shape (number of nodes of all layers,)\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unpack(packed_coef_inter)\n\u001b[0;32m--> 272\u001b[0m loss, coef_grads, intercept_grads \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backprop(\n\u001b[1;32m    273\u001b[0m     X, y, activations, deltas, coef_grads, intercept_grads\n\u001b[1;32m    274\u001b[0m )\n\u001b[1;32m    275\u001b[0m grad \u001b[39m=\u001b[39m _pack(coef_grads, intercept_grads)\n\u001b[1;32m    276\u001b[0m \u001b[39mreturn\u001b[39;00m loss, grad\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:317\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._backprop\u001b[0;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[1;32m    314\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    316\u001b[0m \u001b[39m# Forward propagate\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m activations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_pass(activations)\n\u001b[1;32m    319\u001b[0m \u001b[39m# Get loss\u001b[39;00m\n\u001b[1;32m    320\u001b[0m loss_func_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:173\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass\u001b[0;34m(self, activations)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[39m# For the hidden layers\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;00m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m!=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers_ \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m--> 173\u001b[0m         hidden_activation(activations[i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m])\n\u001b[1;32m    175\u001b[0m \u001b[39m# For the last layer\u001b[39;00m\n\u001b[1;32m    176\u001b[0m output_activation \u001b[39m=\u001b[39m ACTIVATIONS[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_activation_]\n",
      "File \u001b[0;32m~/miniconda3/envs/GISP_init/lib/python3.10/site-packages/sklearn/neural_network/_base.py:44\u001b[0m, in \u001b[0;36minplace_tanh\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minplace_tanh\u001b[39m(X):\n\u001b[1;32m     37\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the hyperbolic tan function inplace.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39m        The input data.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     np\u001b[39m.\u001b[39;49mtanh(X, out\u001b[39m=\u001b[39;49mX)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### LOOCV based on clinic\n",
    "\n",
    "#get all clinics \n",
    "model_nn = MLPClassifier(solver = 'lbfgs', activation = 'tanh', max_iter = 3000 ,hidden_layer_sizes= 12, alpha =1.291549665014884, random_state=10, learning_rate = 'adaptive' )\n",
    "threshold_seq = np.linspace(0,1,6)\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy = 0.5,random_state=42)\n",
    "years_train = [2000, 2001, 2002, 2003, 2004]\n",
    "year = [2006]\n",
    "### subset data based on year FIRST to esnure only clinics that appear in that year are used \n",
    "CIP_data_training_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin(years_train)]\n",
    "CIP_data_testing_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin(year)]\n",
    "\n",
    "clinics = CIP_data_testing_years[\"CLINIC\"].unique()\n",
    "\n",
    "for clinic in clinics:\n",
    "  try:\n",
    "          print(clinic)\n",
    "          train_data = CIP_data_training_years.loc[CIP_data_training_years['CLINIC'] != clinic]\n",
    "          #train data - does not have clinic\n",
    "          X_train = train_data[['MSM','MSMW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West','PREV_REGION', 'PREV_CLINIC','DELTA_REGION']]\n",
    "          y_train = 1 - train_data['Susceptible']\n",
    "          X_train, y_train = oversample.fit_resample(X_train,y_train)\n",
    "\n",
    "          #test data - has clinic \n",
    "          test_data = CIP_data_testing_years.loc[CIP_data_testing_years['CLINIC'] == clinic]\n",
    "          X_test = test_data[['MSM','MSMW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West','PREV_REGION', 'PREV_CLINIC','DELTA_REGION']]\n",
    "          y_test = 1 - test_data['Susceptible']\n",
    "          cipro_R = y_test.sum()/len(y_test) #get prevalence in year before radndom oversampling\n",
    "          print(cipro_R)\n",
    "          X_test, y_test = oversample.fit_resample(X_test,y_test)\n",
    "\n",
    "          # test \n",
    "          model_fit_train = model_nn.fit(X_train, y_train)\n",
    "          y_predict_test = model_fit_train.predict(X_test)\n",
    "          y_predict_proba = model_fit_train.predict_proba(X_test)\n",
    "          get_effective_threshold_region = []\n",
    "          incorrectly_get_X_threshold_region  = []\n",
    "          for threshold in threshold_seq:\n",
    "\n",
    "            y_predict_test = np.where(y_predict_proba[:, 1] > threshold, 1, 0)\n",
    "\n",
    "            tn_test , fp_test , fn_test , tp_test  = confusion_matrix(y_true=y_test, y_pred=y_predict_test).ravel()\n",
    "\n",
    "            sensitivity_test  = tp_test  / (tp_test   + fn_test )\n",
    "            specificity_test   = tn_test / (tn_test + fp_test )\n",
    "  \n",
    "            get_effective_threshold_region .append(sensitivity_test * cipro_R + (1 -  cipro_R)) #q_p\n",
    "            incorrectly_get_X_threshold_region .append((1 - cipro_R) * (1 - specificity_test)) #c_p\n",
    "            plt.plot(get_effective_threshold_region , incorrectly_get_X_threshold_region , color = \"gray\")\n",
    "            plt.plot(1, 1 - cipro_R, marker='.', ls='none', ms=10, color = \"gray\")\n",
    "            plt.plot((1-cipro_R), 0, marker='*', ls='none', ms=10, color = \"gray\")\n",
    "  except ValueError:\n",
    "            oversample = RandomOverSampler(sampling_strategy = 0.5,random_state=42)\n",
    "            print(clinic)\n",
    "            train_data = CIP_data_training_years.loc[CIP_data_training_years['CLINIC'] != clinic]\n",
    "            #train data - does not have clinic\n",
    "            X_train = train_data[['MSM','MSMW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West','PREV_REGION', 'PREV_CLINIC','DELTA_REGION']]\n",
    "            y_train = 1 - train_data['Susceptible']\n",
    "            X_train, y_train = oversample.fit_resample(X_train,y_train)\n",
    "\n",
    "            #test data - has clinic \n",
    "            test_data = CIP_data_testing_years.loc[CIP_data_testing_years['CLINIC'] == clinic]\n",
    "            X_test = test_data[['MSM','MSMW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West','PREV_REGION', 'PREV_CLINIC','DELTA_REGION']]\n",
    "            y_test = 1 - test_data['Susceptible']\n",
    "            cipro_R = y_test.sum()/len(y_test) #get prevalence in year before radndom oversampling\n",
    "            print(cipro_R)\n",
    "            X_test, y_test = oversample.fit_resample(X_test,y_test)\n",
    "\n",
    "            # test \n",
    "            model_fit_train = model_nn.fit(X_train, y_train)\n",
    "            y_predict_test = model_fit_train.predict(X_test)\n",
    "            y_predict_proba = model_fit_train.predict_proba(X_test)\n",
    "            get_effective_threshold_region = []\n",
    "            incorrectly_get_X_threshold_region  = []\n",
    "            for threshold in threshold_seq:\n",
    "\n",
    "              y_predict_test = np.where(y_predict_proba[:, 1] > threshold, 1, 0)\n",
    "\n",
    "              tn_test , fp_test , fn_test , tp_test  = confusion_matrix(y_true=y_test, y_pred=y_predict_test).ravel()\n",
    "\n",
    "              sensitivity_test  = tp_test  / (tp_test   + fn_test )\n",
    "              specificity_test   = tn_test / (tn_test + fp_test )\n",
    "  \n",
    "              get_effective_threshold_region .append(sensitivity_test * cipro_R + (1 -  cipro_R)) #q_p\n",
    "              incorrectly_get_X_threshold_region .append((1 - cipro_R) * (1 - specificity_test)) #c_p\n",
    "              plt.plot(get_effective_threshold_region , incorrectly_get_X_threshold_region , color = \"gray\", alpha = 0.5)\n",
    "              plt.plot(1, 1 - cipro_R, marker='.', ls='none', ms=10, color = \"gray\")\n",
    "              plt.plot((1-cipro_R), 0, marker='*', ls='none', ms=10, color = \"gray\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_years = [2005, 2006, 2007, 2008, 2009, 2010]\n",
    "\n",
    "for year in test_years: \n",
    "    CIP_data_training_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin(years_train)]\n",
    "    CIP_data_testing_years = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin(year)]\n",
    "\n",
    "    clinics = CIP_data_testing_years[\"CLINIC\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = MLPClassifier(solver = 'lbfgs', activation = 'tanh', max_iter = 3000 ,hidden_layer_sizes= 12, alpha =1.291549665014884, random_state=10, learning_rate = 'adaptive' )\n",
    "\n",
    "threshold_seq = np.linspace(0,1,101)\n",
    "labels = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\" ]\n",
    "years = [2006, 2007, 2008, 2009, 2010, 2011]\n",
    "oversample = RandomOverSampler(sampling_strategy = 0.5,random_state=42)\n",
    "text_for_graph = ['0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1']\n",
    "indices = [0,10,20,30,40,50,60,70,80,90,100]\n",
    " #   if (i == 0) | (i == 3):\n",
    " #       axs[i].ylabel(\"Receives unnecessary treatment ($\\omega$(p))\", fontsize=16, **hfont)\n",
    " #   if(i == 3) | (i == 4) | (i == 5):\n",
    " #       axs[i].xlabel(r\"Receives effective treatment ($\\theta$(p))\", fontsize=16, **hfont)\n",
    "\n",
    "fig, axs = plt.subplots(2,3, figsize=(20, 10), facecolor='w', edgecolor='k', sharex = 'all', sharey = 'all')\n",
    "#fig.set_ylabel(\"Receives unnecessary treatment ($\\omega$(p))\", fontsize=16, **hfont)\n",
    "#fig.set_xlabel(r\"Receives effective treatment ($\\theta$(p))\", fontsize=16, **hfont)\n",
    "fig.subplots_adjust(hspace = .15, wspace=.1)\n",
    "axs = axs.ravel()\n",
    "i = 0\n",
    "for year in years: \n",
    "    #train\n",
    "    years_train = np.array(range(year - 5, year))\n",
    "    train_data = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin(years_train)]\n",
    "    X_train = train_data[['MSM','MSMW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West','PREV_REGION', 'PREV_CLINIC','DELTA_REGION']]\n",
    "    y_train = 1 - train_data['Susceptible']\n",
    "    X_train, y_train = oversample.fit_resample(X_train,y_train)\n",
    "    #test\n",
    "    test_data = CIP_data_no_drop.loc[CIP_data_no_drop['YEAR'].isin([year])]\n",
    "    X_test = test_data[['MSM','MSMW', 'Oth/Unk/Missing','Northeast', 'Southeast', 'Southwest', 'West','PREV_REGION', 'PREV_CLINIC','DELTA_REGION']]\n",
    "    y_test = 1 - test_data['Susceptible']\n",
    "    cipro_R_prev = y_test.sum()/len(y_test) #get prevalence in 2011 before radndom oversampling\n",
    "    X_test, y_test = oversample.fit_resample(X_test,y_test)\n",
    "    model_fit_train = model_nn.fit(X_train, y_train)\n",
    "    y_predict_test = model_fit_train.predict(X_test)\n",
    "    y_predict_proba = model_fit_train.predict_proba(X_test)\n",
    "\n",
    "    get_effective_threshold_prev_5 = []\n",
    "    incorrectly_get_X_threshold_prev_5 = [] #no bootstrapping, no 95% CI \n",
    "\n",
    "    for threshold in threshold_seq:\n",
    "\n",
    "        y_predict_test = np.where(y_predict_proba[:, 1] > threshold, 1, 0)\n",
    "\n",
    "        tn_test , fp_test , fn_test , tp_test  = confusion_matrix(y_true=y_test, y_pred=y_predict_test).ravel()\n",
    "\n",
    "        sensitivity_test  = tp_test  / (tp_test   + fn_test )\n",
    "        specificity_test   = tn_test / (tn_test + fp_test )\n",
    "    \n",
    "        get_effective_threshold_prev_5.append(sensitivity_test * cipro_R_prev + (1 -  cipro_R_prev)) #q_p\n",
    "        incorrectly_get_X_threshold_prev_5.append((1 - cipro_R_prev) * (1 - specificity_test)) #c_p\n",
    "    x = 0\n",
    "    axs[i].plot(get_effective_threshold_prev_5, incorrectly_get_X_threshold_prev_5,color = \"black\", linewidth = 3)\n",
    "    axs[i].plot([1, 1-cipro_R_prev], [1-cipro_R_prev, 0], color = \"#e5e5e5\", linestyle=\"--\")\n",
    "\n",
    "    axs[i].set_ylim([0-0.05,0.95])\n",
    "    axs[i].set_xlim([0.84, 1.01])\n",
    "    if (i == 0) | (i == 3):\n",
    "       axs[i].set_ylabel(\"Receives unnecessary treatment ($\\omega$(p))\", fontsize=16, **hfont)\n",
    "    if(i == 3) | (i == 4) | (i == 5):\n",
    "        axs[i].set_xlabel(r\"Receives effective treatment ($\\theta$(p))\", fontsize=16, **hfont)\n",
    "\n",
    "    axs[i].plot(1, 1 - cipro_R_prev, marker='.', ls='none', ms=18, color = \"black\", label = \"Dual\")\n",
    "    axs[i].plot((1-cipro_R_prev), 0, marker='*', ls='none', ms=14, color = \"black\", label = \"Cipro\")\n",
    "    axs[i].text(axs[i].get_xlim()[0] , axs[i].get_ylim()[1] + 0.01, labels[i], fontsize = 16, **hfont)\n",
    "    axs[i].title.set_text(year)\n",
    "    if i == 0:\n",
    "        axs[i].legend(loc = \"upper left\")\n",
    "\n",
    "    for index in indices:\n",
    "        axs[i].plot(get_effective_threshold_prev_5[index], incorrectly_get_X_threshold_prev_5[index], marker='.', ls='none', ms=11, color = \"#b56576\")\n",
    "        if get_effective_threshold_prev_5[index] > 0.996:\n",
    "            axs[i].text(get_effective_threshold_prev_5[index] + 0.002, incorrectly_get_X_threshold_prev_5[index] + 0.001, text_for_graph[x], size = 9)\n",
    "        elif (get_effective_threshold_prev_5[index] > 0.95) & (get_effective_threshold_prev_5[index] < 0.996):\n",
    "            axs[i].text(get_effective_threshold_prev_5[index] + 0.005, incorrectly_get_X_threshold_prev_5[index] - 0.005, text_for_graph[x], size = 9)\n",
    "        else:\n",
    "            axs[i].text(get_effective_threshold_prev_5[index], incorrectly_get_X_threshold_prev_5[index] + 0.025, text_for_graph[x], size = 9)\n",
    "        x = x+1\n",
    "    i += 1   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GISP_init",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37b4cc77837642ee25c4eb6578aebe03e17eb3bb59efdde49edbbc888dbc418f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
