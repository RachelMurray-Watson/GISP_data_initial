{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## read data \n",
    "CIP_data = pd.read_csv(\"CIP_data_encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5957\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "### Step 1: create model and calculate apparent performance metric of interest (P)\n",
    "X = CIP_data[['ANC', 'ATL', 'BAL', 'BHM', 'BOS', 'BUF', 'CAM', 'CHI',\n",
    "       'CIN', 'CLE', 'COL', 'DAL', 'DEN', 'DTR', 'FBG', 'GRB', 'HON', 'IND',\n",
    "       'JAC', 'KCY', 'LAX', 'LBC', 'LVG', 'MIA', 'MIL', 'MIN', 'NOR', 'NYC',\n",
    "       'OKC', 'ORA', 'PHI', 'PHX', 'PON', 'POR', 'RIC', 'SDG', 'SEA', 'SFO',\n",
    "       'SLC', 'STL', 'WDC', 'MSMW', 'MSW', 'Oth/Unk/Missing']]\n",
    "\n",
    "y = CIP_data['Susceptible']\n",
    "\n",
    "print(y.sum())\n",
    "Random_forest_model = RandomForestClassifier(n_estimators=700,min_samples_leaf=100)\n",
    "\n",
    "Random_forest_model_fitted = Random_forest_model.fit(X, y)\n",
    "\n",
    "sample = resample(CIP_data, replace=True, n_samples= len(CIP_data)) ##(a) sample n individuals with replacement\n",
    "\n",
    "X_sample  = sample[['ANC', 'ATL', 'BAL', 'BHM', 'BOS', 'BUF', 'CAM', 'CHI',\n",
    "       'CIN', 'CLE', 'COL', 'DAL', 'DEN', 'DTR', 'FBG', 'GRB', 'HON', 'IND',\n",
    "       'JAC', 'KCY', 'LAX', 'LBC', 'LVG', 'MIA', 'MIL', 'MIN', 'NOR', 'NYC',\n",
    "       'OKC', 'ORA', 'PHI', 'PHX', 'PON', 'POR', 'RIC', 'SDG', 'SEA', 'SFO',\n",
    "       'SLC', 'STL', 'WDC', 'MSMW', 'MSW', 'Oth/Unk/Missing']]\n",
    "y_sample = sample[\"Susceptible\"]\n",
    "y_predict = Random_forest_model_fitted.predict(X_sample)\n",
    "\n",
    "ROC_AUC_random_forest = metrics.roc_auc_score(y_sample, y_predict)\n",
    "print(ROC_AUC_random_forest) # 0.5 again...\n",
    "#print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y, y_predict)) ## but get model accuracy of 0.9470427693866846... so why is the ROC so low? and why is this the same as the nn?\n",
    "\n",
    "\n",
    "\n",
    "#SEED = 42\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                  #  test_size=0.2, \n",
    "                                                  #  random_state=SEED)\n",
    "#rfc = RandomForestClassifier(n_estimators=3, \n",
    "                        #     max_depth=2,\n",
    "                          #   random_state=SEED)\n",
    "# Fit RandomForestClassifier\n",
    "#rfc.fit(X_train, y_train)\n",
    "# Predict the test set labels\n",
    "#y_pred = rfc.predict(X_test)\n",
    "#ROC_AUC_random_forest = metrics.roc_auc_score(y_test, y_pred)\n",
    "#print(ROC_AUC_random_forest)\n",
    "\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3085423204459182\n",
      "0.58549191071322\n",
      "ACCURACY OF THE MODEL:  0.3085423204459182\n"
     ]
    }
   ],
   "source": [
    "X = CIP_data[[ 'MSMW', 'MSW', 'Oth/Unk/Missing']]\n",
    "\n",
    "y = CIP_data['Susceptible']\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 1000, min_samples_leaf=500, class_weight='balanced')\n",
    "model_fit = model.fit(X, y)\n",
    "\n",
    "print(model_fit.score(X,y)) # 0.56\n",
    "\n",
    "y_predict = model_fit.predict(X)\n",
    "\n",
    "ROC_AUC_random_forest = metrics.roc_auc_score(y, y_predict)\n",
    "print(ROC_AUC_random_forest)\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y, y_predict)) ## but get model accuracy of 0.5620116102305155\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28491 78181]\n",
      " [ 1507  4308]]\n"
     ]
    }
   ],
   "source": [
    "##Â try confusion matrix \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_sample, y_predict))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GISP_init",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "113a481252c9d845b94df980c27b1c5a79cf0e399a73b7622446a313d2cec44c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
